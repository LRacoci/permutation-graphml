{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image (1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "rQsYkXeIkL6d",
        "colab": {}
      },
      "source": [
        "#@title ##### License\n",
        "# Copyright 2018 The GraphNets Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#    http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ============================================================================"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bXBusmrp1vaL"
      },
      "source": [
        "# Explore the Darwin's Image graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "FlBiBDZjK-Tl",
        "outputId": "194099c4-89e1-40c5-c611-b5bc68cd0ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "#@title ### Install the Graph Nets library on this Colaboratory runtime  { form-width: \"60%\", run: \"auto\"}\n",
        "#@markdown <br>1. Connect to a local or hosted Colaboratory runtime by clicking the **Connect** button at the top-right.<br>2. Choose \"Yes\" below to install the Graph Nets library on the runtime machine with:<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;```pip install graph_nets```<br> Note, this works both with local and hosted Colaboratory runtimes.\n",
        "\n",
        "install_graph_nets_library = \"Yes\"  #@param [\"Yes\", \"No\"]\n",
        "\n",
        "if install_graph_nets_library.lower() == \"yes\":\n",
        "  print(\"Installing Graph Nets library with:\")\n",
        "  print(\"  $ pip install graph_nets\\n\")\n",
        "  print(\"Output message from command:\\n\")\n",
        "  !pip install graph_nets\n",
        "else:\n",
        "  print(\"Skipping installation of Graph Nets library\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing Graph Nets library with:\n",
            "  $ pip install graph_nets\n",
            "\n",
            "Output message from command:\n",
            "\n",
            "Requirement already satisfied: graph_nets in /usr/local/lib/python3.6/dist-packages (1.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from graph_nets) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from graph_nets) (41.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from graph_nets) (1.12.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from graph_nets) (2.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from graph_nets) (0.7.1)\n",
            "Requirement already satisfied: dm-sonnet<2 in /usr/local/lib/python3.6/dist-packages (from graph_nets) (1.32)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from graph_nets) (1.16.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->graph_nets) (4.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from dm-sonnet<2->graph_nets) (1.10.11)\n",
            "Requirement already satisfied: semantic-version in /usr/local/lib/python3.6/dist-packages (from dm-sonnet<2->graph_nets) (2.6.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from dm-sonnet<2->graph_nets) (0.5.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "31YqFsfHGab3"
      },
      "source": [
        "### Install dependencies locally\n",
        "\n",
        "If you are running this notebook locally (i.e., not through Colaboratory), you will also need to install a few more dependencies. Run the following on the command line to install the graph networks library, as well as a few other dependencies:\n",
        "\n",
        "```\n",
        "pip install graph_nets matplotlib scipy\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ntNJc6x_F4u5"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "tjd3-8PJdK2m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c5c597fe-72b2-482a-8304-58d46142da24"
      },
      "source": [
        "#@title Imports  { form-width: \"20%\" }\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import itertools\n",
        "import time\n",
        "\n",
        "from graph_nets import graphs\n",
        "from graph_nets import utils_np\n",
        "from graph_nets import utils_tf\n",
        "from graph_nets.demos import models\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from scipy import spatial\n",
        "import tensorflow as tf\n",
        "\n",
        "SEED = 1\n",
        "np.random.seed(SEED)\n",
        "tf.set_random_seed(SEED)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz45ongZ9vkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir geo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABNpJNEF3ffE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Debug { form-width: \"20%\" }\n",
        "debug_tags = {\n",
        "#     \"raws\", \n",
        "#     \"source\", \n",
        "#     \"target\",\n",
        "    \"\"\n",
        "}\n",
        "\n",
        "import json\n",
        "def json_default(obj) :\n",
        "    from networkx.readwrite import json_graph\n",
        "    class_name = obj.__class__.__name__\n",
        "    serialization = {\n",
        "        \"Tensor\" : lambda t : {\n",
        "            \"name\" : str(t.name),\n",
        "            \"shape\": str(t.shape),\n",
        "            \"dtype\" : str(t.dtype)\n",
        "            #Tensor(\"placeholders_from_networkxs/nodes:0\", shape=(?, 6), dtype=float64)\n",
        "        },\n",
        "        \"Operation\" : lambda o : {\n",
        "            \"__dict__\" : o.__dict__\n",
        "        },\n",
        "        'DiGraph' : json_graph.adjacency_data,\n",
        "        'int64' : int,\n",
        "        'int32' : int,\n",
        "        'float32' : float,\n",
        "        'ndarray' : list\n",
        "    }\n",
        "    if class_name in serialization:\n",
        "        return serialization[class_name](obj)\n",
        "    \n",
        "    return repr(obj)\n",
        "    \n",
        "    msg = \"Unserializable object {} of type '{}', add class '{}' to rules\".format(obj, type(obj),class_name)\n",
        "    print(msg)\n",
        "    raise TypeError(msg)\n",
        "\n",
        "def dumps(obj, indent = 4, default = json_default) :\n",
        "    return json.dumps(obj, indent = indent, default = default)\n",
        "\n",
        "def debug(obj, tag=\"\"):\n",
        "    global debug_tags\n",
        "    if tag in debug_tags:\n",
        "        print(tag, dumps(obj))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbPd37JlBnn3",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Converters to/from Darwin's format  { form-width: \"20%\" }\n",
        "from graph_nets import blocks\n",
        "from graph_nets import graphs\n",
        "from graph_nets import modules\n",
        "from graph_nets import utils_np\n",
        "from graph_nets import utils_tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import sonnet as snt\n",
        "import tensorflow as tf\n",
        "\n",
        "def darwin_batches_to_networkx_graphs(adjs_gt, node_features, adjs_inp, set_segmentation):\n",
        "    '''\n",
        "    Args:\n",
        "        adjs_gt : adjacency matrix of ground truth, shape = (num_graphs, num_nodes, num_nodes)\n",
        "        node_features :  Matrix of node features, shape = (num_graphs, num_nodes, num_node_features)\n",
        "        adjs_inp : adjacency matrix of input graph, shape = (num_graphs, num_nodes, num_nodes)\n",
        "\n",
        "    Returns:\n",
        "        graphs_tuple : GraphTuple from graph_nets\n",
        "    '''\n",
        "    nxGraphs = []\n",
        "    for adj_gt, node_feature, adj_inp, set_segm in zip(adjs_gt, node_features, adjs_inp,set_segmentation):\n",
        "        nxGraph = nx.from_numpy_matrix(adj_inp, create_using=nx.DiGraph)\n",
        "        #Nodes\n",
        "        nx.set_node_attributes(G = nxGraph, name =\"rgbxy\", values = {\n",
        "            n : val \n",
        "            for n,val in enumerate(node_feature)\n",
        "        })\n",
        "        set_segm = set_segm[\n",
        "            np.uint32(node_feature[:,-2]), \n",
        "            np.uint32(node_feature[:,-1])\n",
        "        ]\n",
        "        nx.set_node_attributes(G = nxGraph, name =\"resp\", values = {\n",
        "            n : val\n",
        "            for n,val in enumerate(set_segm)\n",
        "        })\n",
        "        #Edges\n",
        "        nx.set_edge_attributes(G = nxGraph, name =\"resp\", values = {\n",
        "            (u,v) : adj_gt[u][v]\n",
        "            for (u,v) in nxGraph.edges\n",
        "        })\n",
        "        nxGraphs.append(nxGraph)\n",
        "\n",
        "    return nxGraphs\n",
        "\n",
        "def graphs_tuple_dumps(graphs_tuple):\n",
        "    data_dicts = utils_np.graphs_tuple_to_data_dicts(graphs_tuple)\n",
        "    return json_dumps(data_dicts)\n",
        "\n",
        "def graphs_tuple_loads(string_dump):\n",
        "    data_dicts = json.loads(string_dump)\n",
        "    for data_dict in data_dicts:\n",
        "        for key in data_dict:\n",
        "            data_dict[key] = np.array(data_dict[key])\n",
        "\n",
        "    graphs_tuple = utils_np.data_dicts_to_graphs_tuple(data_dicts)\n",
        "    return graphs_tuple\n",
        "\n",
        "\n",
        "def graphs_tuples_to_darwin_batches(graph_nets):\n",
        "    '''\n",
        "    Args:\n",
        "        graphs_tuple : GraphTuple from graph_nets\n",
        "    Returns:\n",
        "        graph : adjacency matrix of the graph, shape = (num_graphs, num_nodes, num_nodes)\n",
        "        node_features :  Matrix of node features, shape = (num_graphs, num_nodes, num_node_features)\n",
        "    '''\n",
        "    adjs_gt = []\n",
        "    node_features = []\n",
        "    adjs_inp = []\n",
        "    \n",
        "    data_dicts = utils_np.graphs_tuple_to_data_dicts(graph_nets)\n",
        "    for data_dict in data_dicts:\n",
        "        nodes = data_dict['nodes']\n",
        "        num_nodes= len(nodes)\n",
        "        \n",
        "        adj_inp = np.zeros(shape = (num_nodes, num_nodes))\n",
        "        adj_gt = np.zeros(shape = (num_nodes, num_nodes))\n",
        "        \n",
        "        senders = data_dict['senders']\n",
        "        receivers = data_dict['receivers']\n",
        "        edges = data_dict['edges']\n",
        "        \n",
        "        adj_inp[senders, receivers] = 1.0\n",
        "        adjs_gt[senders, receivers] = edges\n",
        "        \n",
        "        adjs_inp.append(adj_inp)\n",
        "        adjs_gt.append(adj_gt)\n",
        "        node_features.append(nodes)\n",
        "    \n",
        "    return np.array(adjs_gt), np.array(node_features), np.array(adjs_inp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "8dDTMylI0BWZ",
        "colab": {}
      },
      "source": [
        "#@title Darwin's Images { form-width: \"20%\" }\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.cm as cm\n",
        "import tensorflow as tf\n",
        "np.random.seed(123)\n",
        "\n",
        "epsilon = 1e-12\n",
        "\n",
        "class GenerateAdjMatrx:\n",
        "\n",
        "    def __init__( self, type_dist=\"D4\" , dim_x = 10, dim_y = 10 ):\n",
        "        self.type_dist = type_dist\n",
        "        self.img_h = dim_x\n",
        "        self.img_w = dim_y\n",
        "        '''\n",
        "        distance D4 or city-block\n",
        "                h-1,w\n",
        "        h,w-1    h,w    h,w+1\n",
        "                h+1,w\n",
        "        '''\n",
        "        self.D4_h = np.array([ 0,  0, 1, -1 ])\n",
        "        self.D4_w = np.array([ -1, 1, 0,  0 ])\n",
        "\n",
        "        '''\n",
        "        distance D8 or chessboard\n",
        "        h-1,w-1   h-1,w   h-1,w+1\n",
        "        h,w-1     h,w     h,w+1\n",
        "        h+1,w-1   h+1,w   h+1,w+1\n",
        "        '''\n",
        "        self.D8_h = np.array([ -1,  0,  1, -1, 1, -1, 0, 1 ])\n",
        "        self.D8_w = np.array([ -1, -1, -1,  0, 0,  1, 1, 1 ])\n",
        "\n",
        "\n",
        "    def adjmatrx_generator( self, dim_x = 10, dim_y = 10 ):\n",
        "        self.img_h = dim_x\n",
        "        self.img_w = dim_y\n",
        "\n",
        "        len_dist = 0\n",
        "        dist_h = []\n",
        "        dist_w = []\n",
        "        num_nodes = self.img_h * self.img_w\n",
        "        self.adjmatrx = np.zeros( ( num_nodes, num_nodes ), dtype = np.float32 )\n",
        "\n",
        "        if self.type_dist == \"D4\":\n",
        "            len_dist = 4\n",
        "            dist_h = self.D4_h\n",
        "            dist_w = self.D4_w\n",
        "        elif self.type_dist == \"D8\":\n",
        "            len_dist = 8\n",
        "            dist_h = self.D8_h\n",
        "            dist_w = self.D8_w\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "        for node in range( num_nodes ):\n",
        "            h = int(node / self.img_w)\n",
        "            w = node % self.img_w\n",
        "            self.adjmatrx[ node, node ] = 1.0\n",
        "            for k in range(len_dist):\n",
        "                hi = h + dist_h[ k ]\n",
        "                wi = w + dist_w[ k ]\n",
        "                if hi >= 0 and hi < self.img_h and wi >= 0 and wi < self.img_w:\n",
        "                    if np.random.randint(2) == 0:\n",
        "                        self.adjmatrx[ node, int(self.img_w * hi + wi) ] = 1.0\n",
        "                        self.adjmatrx[ int(self.img_w * hi + wi), node ] = 1.0\n",
        "\n",
        "        return np.copy(self.adjmatrx.astype( np.float32 ))\n",
        "\n",
        "    def adjmatrx_generator_batch_random( self, num_batch, dim_x = 10, dim_y = 10 ):\n",
        "        self.img_h = dim_x\n",
        "        self.img_w = dim_y\n",
        "\n",
        "        len_dist = 0\n",
        "        dist_h = []\n",
        "        dist_w = []\n",
        "        num_nodes = self.img_h * self.img_w\n",
        "        self.adjmatrx = np.zeros( ( num_batch, num_nodes, num_nodes ), dtype = np.float32 )\n",
        "\n",
        "        if self.type_dist == \"D4\":\n",
        "            len_dist = 4\n",
        "            dist_h = self.D4_h\n",
        "            dist_w = self.D4_w\n",
        "        elif self.type_dist == \"D8\":\n",
        "            len_dist = 8\n",
        "            dist_h = self.D8_h\n",
        "            dist_w = self.D8_w\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "        for n_batch in range(num_batch):\n",
        "            for node in range( num_nodes ):\n",
        "                h = int(node / self.img_w)\n",
        "                w = node % self.img_w\n",
        "                self.adjmatrx[ n_batch, node, node ] = 1.0\n",
        "                for k in range(len_dist):\n",
        "                    hi = h + dist_h[ k ]\n",
        "                    wi = w + dist_w[ k ]\n",
        "                    if hi >= 0 and hi < self.img_h and wi >= 0 and wi < self.img_w:\n",
        "                        self.adjmatrx[ n_batch, node, int(self.img_w * hi + wi) ] = 1.0\n",
        "                        self.adjmatrx[ n_batch, int(self.img_w * hi + wi), node ] = 1.0\n",
        "\n",
        "        return np.copy(self.adjmatrx.astype( np.float32 ))\n",
        "\n",
        "    def adjmatrx_groundthuth( self, img_groundthuth ):\n",
        "        self.img_h = img_groundthuth.shape[ 0 ]\n",
        "        self.img_w = img_groundthuth.shape[ 1 ]\n",
        "\n",
        "        len_dist = 0\n",
        "        dist_h = []\n",
        "        dist_w = []\n",
        "        num_nodes = self.img_h * self.img_w\n",
        "        self.adjmatrx_gt = np.zeros( ( num_nodes, num_nodes ), dtype = np.float32 )\n",
        "\n",
        "        if self.type_dist == \"D4\":\n",
        "            len_dist = 4\n",
        "            dist_h = self.D4_h\n",
        "            dist_w = self.D4_w\n",
        "        elif self.type_dist == \"D8\":\n",
        "            len_dist = 8\n",
        "            dist_h = self.D8_h\n",
        "            dist_w = self.D8_w\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "        for node in range( num_nodes ):\n",
        "            h = int(node / self.img_w)\n",
        "            w = node % self.img_w\n",
        "            self.adjmatrx_gt[ node, node ] = 1.0\n",
        "            for k in range(len_dist):\n",
        "                hi = h + dist_h[ k ]\n",
        "                wi = w + dist_w[ k ]\n",
        "                if hi >= 0 and hi < self.img_h and wi >= 0 and wi < self.img_w:\n",
        "                    if( img_groundthuth[ h, w ] == img_groundthuth[ hi, wi ] ):\n",
        "                        self.adjmatrx_gt[ node, int(self.img_w * hi + wi) ] = 1.0\n",
        "                        self.adjmatrx_gt[ int(self.img_w * hi + wi), node ] = 1.0\n",
        "\n",
        "        return np.copy(self.adjmatrx_gt)\n",
        "\n",
        "\n",
        "    def adjmatrx_loss( self, adj_groundthuth, adj_prediction, dim_x = 10, dim_y = 10 ):\n",
        "        self.img_h = dim_x\n",
        "        self.img_w = dim_y\n",
        "\n",
        "        len_dist = 0\n",
        "        dist_h = []\n",
        "        dist_w = []\n",
        "        num_nodes = self.img_h * self.img_w\n",
        "        self.adj_loss = 0.0\n",
        "\n",
        "        if self.type_dist == \"D4\":\n",
        "            len_dist = 4\n",
        "            dist_h = self.D4_h\n",
        "            dist_w = self.D4_w\n",
        "        elif self.type_dist == \"D8\":\n",
        "            len_dist = 8\n",
        "            dist_h = self.D8_h\n",
        "            dist_w = self.D8_w\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "        n = 0.0\n",
        "        for node in range( num_nodes ):\n",
        "            h = int(node / self.img_w)\n",
        "            w = node % self.img_w\n",
        "\n",
        "            for k in range(len_dist):\n",
        "                hi = h + dist_h[ k ]\n",
        "                wi = w + dist_w[ k ]\n",
        "                if hi >= 0 and hi < self.img_h and wi >= 0 and wi < self.img_w:\n",
        "                    n += 1\n",
        "                    value_pred = adj_prediction[ node, int(self.img_w * hi + wi) ]\n",
        "                    value_ground = adj_groundthuth[ node, int(self.img_w * hi + wi) ]\n",
        "                    self.adj_loss += np.abs( value_ground - value_pred )\n",
        "\n",
        "        self.adj_loss /= n\n",
        "        return self.adj_loss\n",
        "\n",
        "\n",
        "class GenerateImg:\n",
        "    def __init__( \n",
        "            self, \n",
        "            dim_x = 10, \n",
        "            dim_y = 10, \n",
        "            type_dist=\"D4\", \n",
        "            proportion=(0.05, 0.2, 1000), \n",
        "            option_shape='all', \n",
        "            color_rand = True, \n",
        "            noise_data = True \n",
        "    ):\n",
        "        ''' proportion (validation, test, rest is training) '''\n",
        "        self.img_h = dim_x\n",
        "        self.img_w = dim_y\n",
        "        self.num_val = int(proportion[0] * proportion[2])\n",
        "        self.num_test = int(proportion[1] * proportion[2])\n",
        "        self.num_training = int(proportion[2] - self.num_test)\n",
        "        self.option_shape = option_shape\n",
        "        self.color_rand = color_rand\n",
        "        self.noise_data = noise_data\n",
        "        self.type_dist = type_dist\n",
        "\n",
        "    def func_perm(self, img_bgr_, img_ground_truth_, label_all_, A_gt_):\n",
        "        id_perm = np.random.permutation(self.img_h*self.img_w)\n",
        "        #id_perm_w = np.random.permutation(self.img_w)\n",
        "        A_gt = np.zeros_like(A_gt_)\n",
        "        for i in range(A_gt.shape[0]):\n",
        "            for j in range(A_gt.shape[1]):\n",
        "                if A_gt[i][j] == 1. or A_gt[j][i] == 1.:\n",
        "                    A_gt[id_perm[i]][id_perm[j]] = 1.#A_gt[i][j]\n",
        "                    A_gt[id_perm[j]][id_perm[i]] = 1.#A_gt[i][j]\n",
        "\n",
        "        img_bgr = np.zeros((\n",
        "                img_bgr_.shape[0],\n",
        "                img_bgr_.shape[1], \n",
        "                img_bgr_.shape[2]+2\n",
        "        ))\n",
        "        img_ground_truth = np.zeros_like(img_ground_truth_)\n",
        "        label_all = np.zeros_like(label_all_)\n",
        "        for node in range( A_gt.shape[0] ):\n",
        "            h = int(node / self.img_w)\n",
        "            w = node % self.img_w\n",
        "            h_perm = int(id_perm[node] / self.img_w)\n",
        "            w_perm = id_perm[node] % self.img_w\n",
        "\n",
        "            img_bgr[h_perm][w_perm] = img_bgr[h][w]\n",
        "            img_bgr[h_perm][w_perm][3] = h\n",
        "            img_bgr[h_perm][w_perm][4] = w\n",
        "            img_ground_truth[h_perm][w_perm] = img_ground_truth[h][w]\n",
        "            label_all[h_perm][w_perm] = label_all[h][w]\n",
        "\n",
        "        return img_bgr, img_ground_truth, label_all, A_gt\n",
        "\n",
        "    def add_position(self, img_bgr_):\n",
        "        img_bgr = np.zeros((img_bgr_.shape[0],img_bgr_.shape[1], img_bgr_.shape[2]+2))\n",
        "        for h in range(img_bgr_.shape[0]):\n",
        "            for w in range(img_bgr_.shape[1]):\n",
        "                img_bgr[h][w][0:3] = img_bgr_[h][w]\n",
        "                img_bgr[h][w][3] = h\n",
        "                img_bgr[h][w][4] = w\n",
        "        return img_bgr\n",
        "\n",
        "    def load_data(self):\n",
        "        sample_img_train = []\n",
        "        sample_label_train = []\n",
        "        sample_label_split_train = []\n",
        "        sample_A_gt_train = []\n",
        "        sample_B_in_train = []\n",
        "        for n_train in range(self.num_training):\n",
        "            #img_bgr.shape = (10, 10, 3)\n",
        "            img_bgr, img_ground_truth, label_all, A_gt, B_in = self.generate_syntetic_data()\n",
        "            img_bgr = self.add_position(img_bgr)\n",
        "\n",
        "            sample_img_train.append(img_bgr)\n",
        "            sample_label_train.append(img_ground_truth)\n",
        "            sample_label_split_train.append(label_all)\n",
        "            sample_A_gt_train.append(A_gt)\n",
        "            sample_B_in_train.append(B_in)\n",
        "\n",
        "        sample_img_val = []\n",
        "        sample_label_val = []\n",
        "        sample_label_split_val = []\n",
        "        sample_A_gt_val = []\n",
        "        sample_B_in_val = []\n",
        "        for n_val in range(self.num_val):\n",
        "            img_bgr, img_ground_truth, label_all, A_gt, B_in = self.generate_syntetic_data()\n",
        "            img_bgr = self.add_position(img_bgr)\n",
        "\n",
        "            sample_img_val.append(img_bgr)\n",
        "            sample_label_val.append(img_ground_truth)\n",
        "            sample_label_split_val.append(label_all)\n",
        "            sample_A_gt_val.append(A_gt)\n",
        "            sample_B_in_val.append(B_in)\n",
        "\n",
        "        sample_img_test = []\n",
        "        sample_label_test = []\n",
        "        sample_label_split_test = []\n",
        "        sample_A_gt_test = []\n",
        "        sample_B_in_test = []\n",
        "        for n_test in range(self.num_test):\n",
        "            img_bgr, img_ground_truth, label_all, A_gt, B_in = self.generate_syntetic_data()\n",
        "            img_bgr = self.add_position(img_bgr)\n",
        "\n",
        "            sample_img_test.append(img_bgr)\n",
        "            sample_label_test.append(img_ground_truth)\n",
        "            sample_label_split_test.append(label_all)\n",
        "            sample_A_gt_test.append(A_gt)\n",
        "            sample_B_in_test.append(B_in)\n",
        "\n",
        "        self.train_generator = self.batch_generator(\n",
        "                sample_img_train, \n",
        "                sample_label_train, \n",
        "                sample_label_split_train, \n",
        "                sample_A_gt_train,\n",
        "                sample_B_in_train\n",
        "        )\n",
        "        self.valid_generator = self.batch_generator(\n",
        "                sample_img_val, \n",
        "                sample_label_val, \n",
        "                sample_label_split_val, \n",
        "                sample_A_gt_val,\n",
        "                sample_B_in_val\n",
        "        )\n",
        "        self.test_generator = self.batch_generator(\n",
        "                sample_img_test, \n",
        "                sample_label_test, \n",
        "                sample_label_split_test, \n",
        "                sample_A_gt_test,\n",
        "                sample_B_in_test\n",
        "        )\n",
        "\n",
        "    def generate_color(self, color_rand):\n",
        "        if( color_rand ):\n",
        "            b_r_color = np.random.randint( 0, 30 ) #(0-30)\n",
        "            b_g_color = np.random.randint( 0, 30 ) #(0-30)\n",
        "            b_b_color = np.random.randint( 0, 164 ) + 90 #(90-254)\n",
        "\n",
        "            r_r_color = np.random.randint( 0, 104 ) + 150 #(150-254)\n",
        "            r_g_color = np.random.randint( 0, 30 ) #(0-30)\n",
        "            r_b_color = np.random.randint( 0, 10 ) #(0-10)\n",
        "            return [ b_r_color, b_g_color, b_b_color ], [ r_r_color, r_g_color, r_b_color ]\n",
        "        else:\n",
        "            r_color = [ 187.0, 5.0, 13.0 ]\n",
        "            b_color = [ 51.0, 2.0, 151.0 ]\n",
        "            return b_color, r_color\n",
        "\n",
        "    def linear_function( self, x1, y1, x2, y2, xi, yi ):\n",
        "        y = ( ( ( y2 - y1 ) / ( x2 - x1 + 0.001 ) ) * ( xi - x1 ) ) + y1\n",
        "        if yi >= y:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def point_inside_circle( self, x, y, r, xi, yi ):\n",
        "        if ( (xi - x)*(xi - x) + (yi - y)*(yi - y) <= r*r):\n",
        "            return True;\n",
        "        else:\n",
        "            return False;\n",
        "\n",
        "    def point_inside_rectangle( self, x1, y1, x2, y2, xi, yi ):\n",
        "        if ( ( xi >= x1 and xi <= x2 ) and ( yi >= y1 and yi <= y2 ) ):\n",
        "            return True;\n",
        "        else:\n",
        "            return False;\n",
        "\n",
        "    def generate_line( self, img_ground_truth, img, class_blue, class_red ):\n",
        "        x1 = np.random.randint( 0, self.img_h - 1 ) * 1.0\n",
        "        y1 = np.random.randint( 0, self.img_w - 1 ) * 1.0\n",
        "        while True:\n",
        "            x2 = np.random.randint( -50, 50 ) * 1.0\n",
        "            y2 = np.random.randint( -50, 50 ) * 1.0\n",
        "            if x1 != x2 or y1 != y2:\n",
        "                    break\n",
        "\n",
        "        if( self.noise_data == False ):\n",
        "            color_set_blue, set_color_red = self.generate_color(self.color_rand)\n",
        "\n",
        "        for i in range( img.shape[ 0 ] ):\n",
        "            for j in range( img.shape[ 1 ] ):\n",
        "                if( self.noise_data == True ):\n",
        "                    color_set_blue, set_color_red = self.generate_color(self.color_rand)\n",
        "\n",
        "                if self.linear_function( x1, y1, x2, y2, i, j ):\n",
        "                    img[ i, j ] = color_set_blue #R,G,B\n",
        "                    class_blue[ i, j ] = 1.0\n",
        "                else:\n",
        "                    img_ground_truth[ i, j ] = 1.0\n",
        "                    #R,G,B\n",
        "                    img[ i, j ] = set_color_red \n",
        "                    class_red[ i, j ] = 1.0\n",
        "\n",
        "    def generate_circle( self, img_ground_truth, img, class_blue, class_red ):\n",
        "        c_x = np.random.randint( 0, self.img_h - 1 ) * 1.0\n",
        "        c_y = np.random.randint( 0, self.img_w - 1 ) * 1.0\n",
        "        r = np.random.randint( 0, min( self.img_h/2, self.img_h/2 ) ) * 1.0\n",
        "\n",
        "        # blue:0, red:1\n",
        "        color_square = np.random.randint( 0, 1 ) \n",
        "\n",
        "        if( self.noise_data == False ):\n",
        "            color_set_blue, set_color_red = self.generate_color(self.color_rand)\n",
        "\n",
        "        for i in range( img.shape[ 0 ] ):\n",
        "            for j in range( img.shape[ 1 ] ):\n",
        "                if( self.noise_data == True ):\n",
        "                    color_set_blue, set_color_red = self.generate_color(self.color_rand)\n",
        "\n",
        "                if self.point_inside_circle( c_x, c_y, r, i, j ):\n",
        "                    # square blue\n",
        "                    if color_square == 0: \n",
        "                        #R,G,B\n",
        "                        img[ i, j ] = color_set_blue \n",
        "                        class_blue[ i, j ] = 1.0\n",
        "                    else: # square red\n",
        "                        img_ground_truth[ i, j ] = 1.0\n",
        "                        #R,G,B\n",
        "                        img[ i, j ] = set_color_red \n",
        "                        class_red[ i, j ] = 1.0\n",
        "                else:\n",
        "                    # brackground red\n",
        "                    if color_square == 0: \n",
        "                        img_ground_truth[ i, j ] = 1.0\n",
        "                        #R,G,B\n",
        "                        img[ i, j ] = set_color_red \n",
        "                        class_red[ i, j ] = 1.0\n",
        "                # brackground blue\n",
        "                    else: \n",
        "                        #R,G,B\n",
        "                        img[ i, j ] = color_set_blue \n",
        "                        class_blue[ i, j ] = 1.0\n",
        "\n",
        "    def generate_rectangle( self, img_ground_truth, img, class_blue, class_red ):\n",
        "        x1 = np.random.randint( 0, self.img_h - 1 ) * 1.0\n",
        "        y1 = np.random.randint( 0, self.img_w - 1 ) * 1.0\n",
        "        while True:\n",
        "            x2 = np.random.randint( -50, 50 ) * 1.0\n",
        "            y2 = np.random.randint( -50, 50 ) * 1.0\n",
        "            if x1 != x2 or y1 != y2:\n",
        "                break\n",
        "\n",
        "        x_min = min(x1, x2); x_max = max(x1, x2)\n",
        "        y_min = min(y1, y2); y_max = max(y1, y2)\n",
        "\n",
        "        # blue:0, red:1\n",
        "        color_square = np.random.randint( 2 ) \n",
        "\n",
        "        if( self.noise_data == False ):\n",
        "            color_set_blue, set_color_red = self.generate_color(self.color_rand)\n",
        "\n",
        "        for i in range( img.shape[ 0 ] ):\n",
        "            for j in range( img.shape[ 1 ] ):\n",
        "                if( self.noise_data == True ):\n",
        "                    color_set_blue, set_color_red = self.generate_color(self.color_rand)\n",
        "\n",
        "                if self.point_inside_rectangle( x_min, y_min, x_max, y_max, i, j ):\n",
        "                    # square blue\n",
        "                    if color_square == 0: \n",
        "                        #R,G,B (51.0, 2.0, 151.0)\n",
        "                        img[ i, j ] = color_set_blue \n",
        "                        class_blue[ i, j ] = 1.0\n",
        "                    # square red\n",
        "                    else: \n",
        "                        img_ground_truth[ i, j ] = 1.0\n",
        "                        #R,G,B (187.0, 5.0, 13.0)\n",
        "                        img[ i, j ] = set_color_red \n",
        "                        class_red[ i, j ] = 1.0\n",
        "                else:\n",
        "                    # brackground red\n",
        "                    if color_square == 0: \n",
        "                        img_ground_truth[ i, j ] = 1.0\n",
        "                        #R,G,B\n",
        "                        img[ i, j ] = set_color_red \n",
        "                        class_red[ i, j ] = 1.0\n",
        "                    # brackground blue\n",
        "                    else: \n",
        "                        #R,G,B\n",
        "                        img[ i, j ] = color_set_blue \n",
        "                        class_blue[ i, j ] = 1.0\n",
        "\n",
        "    def generate_syntetic_data( self ):\n",
        "        \"\"\" option_shape=[ 'all', 'line', 'circle', 'rectangle'] \"\"\"\n",
        "        label_list = []\n",
        "        img_ground_truth = np.zeros( ( self.img_h, self.img_w ), dtype = np.float32 )\n",
        "        img = np.zeros( ( self.img_h, self.img_w, 3 ), dtype = np.float32 )\n",
        "        class_blue = np.zeros( ( self.img_h, self.img_w ), dtype = np.float32 )\n",
        "        class_red = np.zeros( ( self.img_h, self.img_w ), dtype = np.float32 )\n",
        "\n",
        "        '''line, square, grill, rectangle, cross'''\n",
        "        if self.option_shape == 'line':\n",
        "            sample_type = 0\n",
        "        elif self.option_shape == 'circle':\n",
        "            sample_type = 1\n",
        "        elif self.option_shape == 'rectangle':\n",
        "            sample_type = 2\n",
        "        else: \n",
        "            sample_type = np.random.randint( 3 ) #0,1,2\n",
        "\n",
        "        if sample_type == 0:\n",
        "            self.generate_line( img_ground_truth, img, class_blue, class_red )\n",
        "        elif sample_type == 1:\n",
        "            self.generate_circle( img_ground_truth, img, class_blue, class_red )\n",
        "        else:\n",
        "            self.generate_rectangle( img_ground_truth, img, class_blue, class_red )\n",
        "\n",
        "        label_list.append( class_blue )\n",
        "        label_list.append( class_red )\n",
        "        # 2 classes generates\n",
        "        label_all = np.dstack( label_list ).astype( np.float32 ) \n",
        "        r, g, b = cv2.split( img )\n",
        "        img_bgr = cv2.merge( [ b, g, r ] )\n",
        "\n",
        "        gen_adj = GenerateAdjMatrx( type_dist = self.type_dist )\n",
        "        A_gt = gen_adj.adjmatrx_groundthuth( img_ground_truth )\n",
        "\n",
        "        B_in = gen_adj.adjmatrx_groundthuth(img_ground_truth * 0)\n",
        "\n",
        "        return img_bgr, img_ground_truth, label_all, A_gt, B_in\n",
        "\n",
        "    def batch_generator( self, db_img, db_label, db_label_split, db_A_gt, db_B_in):\n",
        "        def gen_batch( batch_size ):\n",
        "            for offset in range(0, len(db_img), batch_size):\n",
        "                files_img = db_img[offset:offset+batch_size]\n",
        "                files_label = db_label[offset:offset+batch_size]\n",
        "                files_label_split = db_label_split[offset:offset+batch_size]\n",
        "                files_A_gt = db_A_gt[offset:offset+batch_size]\n",
        "                files_B_in = db_B_in[offset:offset+batch_size]\n",
        "\n",
        "                yield tuple([\n",
        "                        np.array(files_A_gt), \n",
        "                        np.array(files_img).reshape(len(files_img),self.img_h*self.img_w,-1), \n",
        "                        np.array( files_label ), \n",
        "                        np.array(files_B_in)\n",
        "                ])\n",
        "        return gen_batch\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "N9DnpO9k8U7a",
        "colab": {}
      },
      "source": [
        "#@title Graph Plot Helper Class  { form-width: \"30%\" }\n",
        "\n",
        "class CDisplay:\n",
        "\n",
        "    def display_images( self, img, label, label_by_classes, name ):\n",
        "        b, g, r = cv2.split( img )\n",
        "        img_rgb = cv2.merge( [ r, g, b ] )\n",
        "\n",
        "        fig = plt.figure()\n",
        "\n",
        "        plt.subplot( 2, 2, 1 )\n",
        "        plt.title('image, X', fontsize=9)\n",
        "        plt.imshow( img_rgb.astype(np.uint8) )\n",
        "\n",
        "        plt.subplot( 2, 2, 2 )\n",
        "        plt.title('label, Y', fontsize=9)\n",
        "        plt.imshow( label )\n",
        "\n",
        "        plt.subplot( 2, 2, 3 )\n",
        "        plt.title('Class blue', fontsize=9)\n",
        "        plt.imshow( label_by_classes[ :, :, 0 ].astype(np.uint8) )\n",
        "\n",
        "        plt.subplot( 2, 2, 4 )\n",
        "        plt.title('Class red', fontsize=9)\n",
        "        plt.imshow( label_by_classes[ :, :, 1 ].astype(np.uint8) )\n",
        "\n",
        "        plt.show()\n",
        "        fig.savefig( name, dpi = fig.dpi )\n",
        "\n",
        "    def display_results( self, img, label, pred, name ):\n",
        "        b, g, r = cv2.split( img )\n",
        "        img_rgb = cv2.merge( [ r, g, b ] )\n",
        "\n",
        "        fig = plt.figure()\n",
        "\n",
        "        plt.subplot( 1, 3, 1 )\n",
        "        plt.title('image, X', fontsize=9)\n",
        "        plt.imshow( img_rgb.astype(np.uint8) )\n",
        "\n",
        "        plt.subplot( 1, 3, 2 )\n",
        "        plt.title('label, Y', fontsize=9)\n",
        "        plt.imshow( label.astype(np.uint8) )\n",
        "\n",
        "        plt.subplot( 1, 3, 3 )\n",
        "        plt.title('prediction', fontsize=9)\n",
        "        plt.imshow( pred.astype(np.uint8) )\n",
        "\n",
        "        plt.show()\n",
        "        fig.savefig( name, dpi = fig.dpi )\n",
        "\n",
        "    def display_neighborhood(\n",
        "            self, \n",
        "            img_orig, \n",
        "            img_pred, \n",
        "            adj_original, \n",
        "            adj_update,\n",
        "            img_h, \n",
        "            img_w, \n",
        "            name \n",
        "    ):\n",
        "\n",
        "        fig = plt.figure()\n",
        "        ax1 = plt.subplot(121)\n",
        "        ax2 = plt.subplot(122)\n",
        "\n",
        "        ax1.set_title('Img Original', fontsize=9)\n",
        "        ax1.imshow( img_orig.astype(np.uint8) )\n",
        "\n",
        "        ax2.set_title('Img Prediction', fontsize=9)\n",
        "        ax2.imshow( img_pred.astype(np.uint8) )\n",
        "\n",
        "        #plt.colorbar(mappable=ax1, cax=None, ax=None)\n",
        "        #synt_data = Parallel(n_jobs=-1)( \\\n",
        "        #    delayed(generate_syntetic_data)(self.img_h, self.img_w) for bt in range( batch_size ))\n",
        "\n",
        "        #Parallel(n_jobs=3)( delayed(self.display_adj_mtrx)( img_h, img_w, h, w, ax1, adj_original[h,w] ) for w in range(img_h * img_w) for h in range(img_h * img_w) )\n",
        "        #display_adj_mtrx( img_h, img_w, h, w, ax1, value_adj_original )\n",
        "\n",
        "        #-- for h in range(img_h * img_w):\n",
        "        #--     for w in range(img_h * img_w):\n",
        "        #--         self.display_adj_mtrx( img_h, img_w, h, w, ax1, adj_original[h,w] )\n",
        "        #---ch = []\n",
        "        #---cw = []\n",
        "        #---for i in range(img_h):\n",
        "        #---    for j in range(img_w):\n",
        "        #---        #ax1.plot(i,j, 'o', c='r', markersize=4)\n",
        "        #---        #ax2.plot(i,j, 'o', c='r', markersize=4)\n",
        "        #---        ch.append(i)\n",
        "        #---        cw.append(j)\n",
        "        #---ax1.plot(ch,cw, 'o', c='r', markersize=4)\n",
        "        #---ax2.plot(ch,cw, 'o', c='r', markersize=4)\n",
        "\n",
        "        ch = np.arange(img_h)\n",
        "        cw = np.arange(img_w)\n",
        "        xx, yy = np.meshgrid(ch, cw)\n",
        "        ax1.plot(xx,yy, 'o', c='w', markersize=1)\n",
        "        ax2.plot(xx,yy, 'o', c='r', markersize=1)\n",
        "\n",
        "\n",
        "        for h in range(img_h * img_w):\n",
        "                for w in range(h, img_h * img_w):\n",
        "                        if( h != w ):\n",
        "                                hi = [ int(h / img_w), int(w / img_w) ]\n",
        "                                wi = [ int(h % img_w), int(w % img_w) ]\n",
        "                                #circle_t1 = plt.Circle((h, w), 0.1, color='r')\n",
        "                                #circle_t2 = plt.Circle((w, h), 0.1, color='r')\n",
        "                                #ax1.add_artist(circle_t1)\n",
        "                                #ax1.add_artist(circle_t2)\n",
        "                                if adj_original[h,w] >= epsilon:\n",
        "                                        ax1.plot(\n",
        "                                                wi, \n",
        "                                                hi, \n",
        "                                                linewidth=0.7, \n",
        "                                                color='w', \n",
        "                                                linestyle='-',\n",
        "                                                alpha=adj_original[h,w], \n",
        "                                                marker='o', \n",
        "                                                markersize=1.0 \n",
        "                                        )\n",
        "                                if (adj_update[h,w] >= epsilon):\n",
        "                                        ax2.plot(\n",
        "                                                wi, \n",
        "                                                hi, \n",
        "                                                linewidth=0.7, \n",
        "                                                color='r', \n",
        "                                                linestyle='-',\n",
        "                                                alpha = round( adj_update[h,w], 2 ) \n",
        "                                        )\n",
        "\n",
        "        #----ax2.set_title('Img Prediction', fontsize=9)\n",
        "        #----ax2.imshow( img_pred.astype(np.uint8) )\n",
        "        #----for h in range(img_h * img_w):\n",
        "                #----for w in range(h, img_h * img_w):\n",
        "                        #----hi = [ int(h / img_w), int(w / img_w) ]\n",
        "                        #----wi = [ int(h % img_w), int(w % img_w) ]\n",
        "                        #circle_t1 = plt.Circle((h, w), 0.1, color='r')\n",
        "                        #circle_t2 = plt.Circle((w, h), 0.1, color='r')\n",
        "                        #ax2.add_artist(circle_t1)\n",
        "                        #ax2.add_artist(circle_t2)\n",
        "                        #if ( adj_update[h,w] < 1e-12 ): print ( adj_update[h,w] )\n",
        "                        #abc = (adj_update[h,w]*10).astype(int)/10.0\n",
        "                        #print (\"-------> \", abc )\n",
        "                        #----if (adj_update[h,w] >= epsilon):\n",
        "                                #print (\"adj_update[h,w]: \", round( adj_update[h,w], 2 ) )\n",
        "                                #value_color = int(adj_update[h,w]*10)#min(1,int(adj_update[h,w]*10))\n",
        "                                #print( \"--> \", value_color )\n",
        "                                #ax2.plot(hi, wi, linewidth=2.0, color=colors[value_color], linestyle='-')\n",
        "                                #----ax2.plot(wi, hi, linewidth=2.0, color='r', linestyle='-', \\\n",
        "                                        #----alpha = round( adj_update[h,w], 2 ) )\n",
        "\n",
        "        #plt.scatter(data2_x, data2_y, marker='s', c=data2[data2_x, data2_y])\n",
        "        #for h in range(img_h):\n",
        "        #    for w in range(img_w):\n",
        "        #        circle_t = plt.Circle((h, w), 0.1, color='r')\n",
        "        #        ax1.add_artist(circle_t)\n",
        "        #        ax2.add_artist(circle_t)\n",
        "\n",
        "        #plt.show()\n",
        "        fig.savefig( name, dpi = 400 ) #dpi = fig.dpi,\n",
        "\n",
        "    def display_neighborhood2( \n",
        "        self, \n",
        "        img_orig, \n",
        "        img_pred, \n",
        "        adj_original, \n",
        "        adj_update, \n",
        "        img_h, \n",
        "        img_w, \n",
        "        name \n",
        "    ):\n",
        "        '''Show the graph using the gt classifier as background(img_orig)'''\n",
        "        fig = plt.figure()\n",
        "        #plt.figure()\n",
        "        #fig = plt.imshow(img_orig)\n",
        "        plt.imshow(img_orig)\n",
        "        #plt.imshow(data1, interpolation='nearest', cmap='binary', vmin=0.0, vmax=1.0)\n",
        "        h = []\n",
        "        w = []\n",
        "        for i in range(img_h):\n",
        "                for j in range(img_w):\n",
        "                        h.append(i)\n",
        "                        w.append(j)\n",
        "        #plt.scatter(h, w, marker='o', c='r', markersize=0.2)\n",
        "        plt.plot(h,w, 'o', c='r', markersize=3)\n",
        "        for h in range(img_h * img_w):\n",
        "                for w in range(h, img_h * img_w):\n",
        "                        if (adj_update[h,w] >= epsilon):\n",
        "                                hi = np.array([int(h / img_w), int(w / img_w)],dtype=np.int8)\n",
        "                                wi = np.array([ int(h % img_w), int(w % img_w)],dtype=np.int8)\n",
        "                                plt.plot(wi, hi, linewidth=2.0, color='r', linestyle='-', \\\n",
        "                                        alpha = round( adj_update[h,w], 2 ))\n",
        "        #---plt.plot([[1, 2], [2, 5]],[[5, 1], [3, 7]], linewidth=2.0, color='r', linestyle='-', alpha=0.5)\n",
        "        fig.savefig( name, dpi = 100 ) #dpi = fig.dpi,\n",
        "\n",
        "    def displayAdjMatrix( self, adj_update, name ):\n",
        "        fig = plt.figure()\n",
        "        plt.imshow( adj_update )#.astype(np.uint8) )\n",
        "        plt.show()\n",
        "        fig.savefig( name, dpi = fig.dpi )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm8JPSjwmeeG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_batch_gen():\n",
        "    #------------------ Geometric shape synthetic data ------------------\n",
        "    num_samples = 7\n",
        "    num_points = 9 #square\n",
        "\n",
        "    dim_h = int(np.sqrt(num_points))\n",
        "    dim_w = int(np.sqrt(num_points))\n",
        "    #num_data = 1000\n",
        "    display = CDisplay()\n",
        "    #synthetic data\n",
        "    gen_dataset = GenerateImg(\n",
        "            dim_x = dim_h, \n",
        "            dim_y = dim_w, \n",
        "            proportion=(0.05, 0.2, num_samples) \n",
        "    )\n",
        "    gen_dataset.load_data()\n",
        "\n",
        "    epochs=1\n",
        "    batch_size=3\n",
        "    for epoch in range(epochs):\n",
        "        print(\"\\n########## epoch \" + str(epoch+1) + \" ##########\")\n",
        "        gen_trainig = gen_dataset.train_generator( batch_size = batch_size )\n",
        "        counter = 0\n",
        "        for gt_graph, set_feature, set_segmentation, in_graph in gen_trainig:\n",
        "            print(\"---- batch ----\")\n",
        "            print(\"gt_graph.shape: \", gt_graph.shape)\n",
        "            print(gt_graph)\n",
        "            print(\"set_feature.shape: \", set_feature.shape)\n",
        "            print(set_feature)\n",
        "            print(\"set_segmentation.shape: \", set_segmentation.shape)\n",
        "            print(set_segmentation)\n",
        "            print(\"in_graph.shape: \", in_graph.shape)\n",
        "            print(in_graph)\n",
        "            \n",
        "            nxGraphs = darwin_batches_to_networkx_graphs(gt_graph, set_feature, in_graph, set_segmentation)\n",
        "            \n",
        "            #display = geometric_shape_dataset.CDisplay()\n",
        "            shape_img = set_feature.shape\n",
        "            dim_h, dim_w = int(np.sqrt(shape_img[1])), int(np.sqrt(shape_img[1]))\n",
        "            img_set_feature = set_feature.reshape(\n",
        "                    shape_img[0], \n",
        "                    dim_h, \n",
        "                    dim_w, \n",
        "                    shape_img[2]\n",
        "            )\n",
        "            img_set_feature = img_set_feature[:,:,:,0:3]\n",
        "            for k in range(gt_graph.shape[0]):\n",
        "                display.display_neighborhood(\n",
        "                        img_set_feature[k], \n",
        "                        set_segmentation[k],\n",
        "                        in_graph[k], gt_graph[k], \n",
        "                        dim_h, \n",
        "                        dim_w, \n",
        "                        'geo/img_'+str(counter)+'.png'\n",
        "                ) #the second gt_graph will be the prediction\n",
        "                counter += 1\n",
        "            break\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "TrGithqWUML7",
        "colab": {}
      },
      "source": [
        "#@title Helper functions  { form-width: \"20%\" }\n",
        "\n",
        "# pylint: disable=redefined-outer-name\n",
        "\n",
        "def print_graph(g):\n",
        "    for s, t, w in g.edges(data=True):\n",
        "        if 'features' not in w:\n",
        "            print(s, t, w, \"(problem)\")\n",
        "        else:\n",
        "            print(s, t, w, \"(ok)\")\n",
        "\n",
        "def print_graphs(gs):\n",
        "    for g in gs:\n",
        "        print(\"----------------------------------------------------------------------------\")\n",
        "        print_graph(g)\n",
        "        print(\"----------------------------------------------------------------------------\")\n",
        "\n",
        "DISTANCE_WEIGHT_NAME = \"distance\"  # The name for the distance edge attribute.\n",
        "\n",
        "def pairwise(iterable):\n",
        "    \"\"\"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\"\"\n",
        "    a, b = itertools.tee(iterable)\n",
        "    next(b, None)\n",
        "    return zip(a, b)\n",
        "\n",
        "def set_diff(seq0, seq1):\n",
        "    \"\"\"Return the set difference between 2 sequences as a list.\"\"\"\n",
        "    return list(set(seq0) - set(seq1))\n",
        "\n",
        "def to_one_hot(indices, max_value, axis=-1):\n",
        "    one_hot = np.eye(max_value)[indices]\n",
        "    if axis not in (-1, one_hot.ndim):\n",
        "        one_hot = np.moveaxis(one_hot, -1, axis)\n",
        "    return one_hot\n",
        "\n",
        "def create_feature(features, fields = None):\n",
        "    return np.hstack(\n",
        "        [np.array(features[field], dtype=float) for field in fields if field in features] if fields else\n",
        "        [np.array(features[field], dtype=float) for field in features]\n",
        "    )\n",
        " \n",
        "def generate_raw_graphs(rand, batch_size, min_max_nodes, geo_density, seet = 0):  \n",
        "    #------------------ Geometric shape synthetic data ------------------\n",
        "    num_samples = 1000\n",
        "    num_points = rand.randint(*min_max_nodes)\n",
        "\n",
        "    dim_h = int(np.sqrt(num_points))\n",
        "    dim_w = int(np.sqrt(num_points))\n",
        "    #num_data = 1000\n",
        "\n",
        "    #synthetic data\n",
        "    gen_dataset = GenerateImg(\n",
        "            dim_x = dim_h, \n",
        "            dim_y = dim_w, \n",
        "            proportion=(0.05, 0.2, num_samples) \n",
        "    )\n",
        "    gen_dataset.load_data()\n",
        "\n",
        "    epochs=1\n",
        "    for epoch in range(epochs):\n",
        "        gen_trainig = gen_dataset.train_generator( batch_size = batch_size )\n",
        "        counter = 0\n",
        "        for gt_graph, set_feature, set_segmentation, in_graph in gen_trainig:\n",
        "            counter += 1\n",
        "            nxGraphs = darwin_batches_to_networkx_graphs(gt_graph, set_feature, in_graph, set_segmentation)\n",
        "            debug(nxGraphs, \"raws\")\n",
        "            return nxGraphs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "6oEV1OC3UQAc",
        "outputId": "2e6a68ee-bc09-4eeb-b207-73ee89e5599d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#@title #Visualize example graphs  { form-width: \"30%\" }\n",
        "def rgb_from_hex(h):\n",
        "    if h[0] != '#' or len(h) != 7:\n",
        "        raise ValueError(\"'{}' should be '#' followed by 6 HEX chars\".format(h))\n",
        "    h = h.lstrip('#')\n",
        "    h = h.upper()\n",
        "    invalid_chars = set(list(h)) - set(list(\"0123456789ABCDEF\"))\n",
        "    if invalid_chars:\n",
        "        raise ValueError(\"Incorrect chars: \\{{}\\}\".format(', '.format(invalid_chars)))\n",
        "    return tuple(int(h[i:i+2], 16)/255.0 for i in [0, 2 ,4])\n",
        "\n",
        "#@markdown ##General Visual Params\n",
        "\n",
        "node_size=200 #@param{type:\"slider\", min:128, max:2048, step:1}\n",
        "node_hex_color = \"#808080\" #@param {type:\"string\"}\n",
        "node_color = rgb_from_hex(node_hex_color)\n",
        "node_linewidth=1.0 #@param{type:\"slider\", min:0.1, max:3.0, step:0.1}\n",
        "edge_width=0.2 #@param{type:\"slider\", min:0.1, max:3.0, step:0.1}\n",
        "edge_style = \"dashed\" #@param [\"solid\", \"dashed\", \"dotted\", \"dashdot\"]\n",
        "start_color=\"w\"\n",
        "end_color=\"k\"\n",
        "\n",
        "#@markdown ##Solution Visual Paramters\n",
        "solution_node_hex_color = \"#3DFF3D\" #@param {type:\"string\"}\n",
        "solution_node_color = rgb_from_hex(solution_node_hex_color)\n",
        "solution_node_linewidth=0.6 #@param{type:\"slider\", min:0.1, max:6.0, step:0.1}\n",
        "solution_edge_width=6.0 #@param{type:\"slider\", min:0.1, max:4.0, step=0.1}\n",
        "solution_edge_style = \"solid\" #@param [\"solid\", \"dashed\", \"dotted\", \"dashdot\"]\n",
        "\n",
        "\n",
        "#@markdown ##Specific Parameters\n",
        "\n",
        "seed = 5  #@param{type: 'integer'}\n",
        "rand = np.random.RandomState(seed=seed)\n",
        "\n",
        "num_examples = 4  #@param{type: 'integer'}\n",
        "\n",
        "\n",
        "min_nodes = 34 #@param {type:\"slider\", min:4, max:64, step:1}\n",
        "max_nodes = 36 #@param {type:\"slider\", min:4, max:64, step:1}\n",
        "\n",
        "theta = 12  #@param{type:\"slider\", min:4, max:64, step:1}\n",
        "#@markdown Large values (1000+) make trees. Try 20-60 for good non-trees.\n",
        "\n",
        "horizontal_length = 20 #@param{type: 'integer'}\n",
        "graphs_per_column = 1 #@param{type: 'integer'}\n",
        "\n",
        "min_max_nodes = (min_nodes, max_nodes)\n",
        "\n",
        "graphs = generate_raw_graphs(\n",
        "    rand,\n",
        "    num_examples,\n",
        "    min_max_nodes,\n",
        "    theta\n",
        ")\n",
        "\n",
        "num = 2*min(num_examples, 16)\n",
        "w = 2*graphs_per_column\n",
        "size = horizontal_length/w\n",
        "h = int(np.ceil(num / w))\n",
        "fig = plt.figure(num=40, figsize=(w*size, h * size))\n",
        "fig.clf()\n",
        "for k, raw in enumerate(graphs):\n",
        "    aux = nx.get_node_attributes(raw,'rgbxy')\n",
        "    node_rgbxy = []\n",
        "    for u in aux:\n",
        "        node_rgbxy.append(aux[len(node_rgbxy)])\n",
        "    node_rgbxy = np.array(node_rgbxy) \n",
        "\n",
        "    x = np.uint32(node_rgbxy[:,-2])\n",
        "    y = np.uint32(node_rgbxy[:,-1])\n",
        "    \n",
        "    img_w, img_h = max(x)+1, max(y)+1\n",
        "\n",
        "    img_orig = np.zeros(shape=(img_w, img_h, 3))\n",
        "    img_orig[x,y] = np.uint8(node_rgbxy[:,:3])\n",
        "\n",
        "    aux = nx.get_node_attributes(raw,'resp')\n",
        "    node_resp = []\n",
        "    for u in aux:\n",
        "        node_resp.append(aux[len(node_resp)])\n",
        "    node_resp = np.array(node_resp)\n",
        "    \n",
        "    img_pred = np.zeros(shape=(img_w, img_h))\n",
        "    img_pred[x,y] = np.uint8(node_resp)\n",
        "\n",
        "    src_ax = fig.add_subplot(h, w, 2*k + 1)\n",
        "    tgt_ax = fig.add_subplot(h, w, 2*k + 2)\n",
        "\n",
        "    src_ax.set_title('Img Original', fontsize=9)\n",
        "    src_ax.imshow( img_orig )\n",
        "\n",
        "    tgt_ax.set_title('Img Prediction', fontsize=9)\n",
        "    tgt_ax.imshow( img_pred )\n",
        "\n",
        "    xx, yy = np.meshgrid(\n",
        "        np.arange(img_h), \n",
        "        np.arange(img_w)\n",
        "    )\n",
        "    src_ax.plot(xx,yy, 'o', c='w', markersize=1)\n",
        "    tgt_ax.plot(xx,yy, 'o', c='r', markersize=1)\n",
        "\n",
        "    for u,v in raw.edges():\n",
        "        hi = [raw.node[u][\"rgbxy\"][3],raw.node[u][\"rgbxy\"][4]]\n",
        "        wi = [raw.node[v][\"rgbxy\"][3],raw.node[v][\"rgbxy\"][4]]\n",
        "        if raw[u][v][\"weight\"] >= epsilon:\n",
        "            src_ax.plot(\n",
        "                wi, \n",
        "                hi, \n",
        "                linewidth=0.7, \n",
        "                color='w', \n",
        "                linestyle='-',\n",
        "                alpha=raw[u][v][\"weight\"], \n",
        "                marker='o', \n",
        "                markersize=1.0 \n",
        "            )\n",
        "        if (raw[u][v][\"resp\"] >= epsilon):\n",
        "            tgt_ax.plot(\n",
        "                wi, \n",
        "                hi, \n",
        "                linewidth=0.7, \n",
        "                color='r', \n",
        "                linestyle='-',\n",
        "                alpha = round( raw[u][v][\"resp\"], 2 ) \n",
        "            )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXiquKfdoc_3",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Source and Target from Raw { form-width: \"20%\" }\n",
        "def source_from_raw(raw):\n",
        "    source = nx.DiGraph()\n",
        "    # Nodes\n",
        "    fields = ('rgbxy','resp')\n",
        "    for node, feature in raw.nodes(data=True):\n",
        "        feature = dict(feature)\n",
        "        feature['resp'] = np.zeros(shape = feature['resp'].shape)\n",
        "        source.add_node(\n",
        "            node, features=create_feature(feature, fields)\n",
        "        )\n",
        "    # Edges\n",
        "    fields = ('weight',)\n",
        "    for receiver, sender, feature in raw.edges(data=True):\n",
        "        source.add_edge(\n",
        "            sender, receiver, features=create_feature(feature, fields)\n",
        "        )\n",
        "    \n",
        "    source.graph[\"features\"] = np.array([0.0])\n",
        "    \n",
        "    debug(source, \"source\")\n",
        "    \n",
        "    return source\n",
        "\n",
        "def target_from_raw(raw):\n",
        "    target = nx.DiGraph()\n",
        "    solution_length = 0\n",
        "    # Nodes\n",
        "    fields = ('rgbxy','resp')\n",
        "    for node, feature in raw.nodes(data=True):\n",
        "        feature = dict(feature)\n",
        "        feature['rgbxy'] = np.zeros(shape = feature['rgbxy'].shape)\n",
        "        target.add_node(\n",
        "            node, features=create_feature(feature, fields)\n",
        "        )\n",
        "    # Edges\n",
        "    fields = ('resp',)\n",
        "    for receiver, sender, feature in raw.edges(data=True):\n",
        "        target.add_edge(\n",
        "            sender, receiver, features=create_feature(feature, fields)\n",
        "        )\n",
        "        solution_length += int(feature[\"resp\"])\n",
        "    \n",
        "    target.graph[\"features\"] = np.array([solution_length], dtype=float)\n",
        "    \n",
        "    debug(target, \"target\")\n",
        "    \n",
        "    return target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "H1UBEloigM8q",
        "colab": {}
      },
      "source": [
        "#@title Helper functions for setup training { form-width: \"20%\" }\n",
        "\n",
        "def generate_networkx_graphs(raw_graphs):\n",
        "    \"\"\"Generate graphs for training.\n",
        "\n",
        "    Args:\n",
        "        rand: A random seed (np.RandomState instance).\n",
        "        num_examples: Total number of graphs to generate.\n",
        "        min_max_nodes: A 2-tuple with the [lower, upper) number of nodes per\n",
        "            graph. The number of nodes for a graph is uniformly sampled within this\n",
        "            range.\n",
        "        geo_density: (optional) A `float` threshold parameters for the geographic\n",
        "            threshold graph's threshold. Default= the number of nodes.\n",
        "\n",
        "    Returns:\n",
        "        source_graphs: The list of source graphs.\n",
        "        target_graphs: The list of output graphs.\n",
        "        raw_graphs: The list of generated graphs.\n",
        "    \"\"\"\n",
        "\n",
        "    source_graphs = [source_from_raw(raw) for raw in raw_graphs]\n",
        "    target_graphs = [target_from_raw(raw) for raw in raw_graphs]\n",
        "\n",
        "    return source_graphs, target_graphs\n",
        "\n",
        "\n",
        "# pylint: disable=redefined-outer-name\n",
        "def create_placeholders(raw_graphs):\n",
        "    \"\"\"Creates placeholders for the model training and evaluation.\n",
        "\n",
        "    Args:\n",
        "        rand: A random seed (np.RandomState instance).\n",
        "        batch_size: Total number of graphs per batch.\n",
        "        min_max_nodes: A 2-tuple with the [lower, upper) number of nodes per\n",
        "            graph. The number of nodes for a graph is uniformly sampled within this\n",
        "            range.\n",
        "        geo_density: A `float` threshold parameters for the geographic threshold graph's\n",
        "            threshold. Default= the number of nodes.\n",
        "\n",
        "    Returns:\n",
        "        source_ph: The source graph's placeholders, as a graph namedtuple.\n",
        "        target_ph: The target graph's placeholders, as a graph namedtuple.\n",
        "    \"\"\"\n",
        "    # Create some example data for inspecting the vector sizes.\n",
        "    source_graphs = [source_from_raw(raw) for raw in raw_graphs]\n",
        "    source_ph = utils_tf.placeholders_from_networkxs(\n",
        "        source_graphs,\n",
        "        force_dynamic_num_graphs=True\n",
        "    )\n",
        "\n",
        "    target_graphs = [target_from_raw(raw) for raw in raw_graphs]\n",
        "\n",
        "    target_ph = utils_tf.placeholders_from_networkxs(\n",
        "        target_graphs,\n",
        "        force_dynamic_num_graphs=True\n",
        "    )\n",
        "    return source_ph, target_ph\n",
        "\n",
        "\n",
        "def create_loss_ops(target_op, output_ops):\n",
        "    loss_ops = [\n",
        "        tf.losses.softmax_cross_entropy(target_op.edges, output_op.edges)\n",
        "        for output_op in output_ops\n",
        "    ]\n",
        "    return loss_ops\n",
        "\n",
        "\n",
        "def make_all_runnable_in_session(*args):\n",
        "    \"\"\"Lets an iterable of TF graphs be output from a session as NP graphs.\"\"\"\n",
        "    return [utils_tf.make_runnable_in_session(a) for a in args]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3WEltD_EL0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Model definition { form-width: \"20%\" }\n",
        "\n",
        "# Copyright 2018 The GraphNets Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#    http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ============================================================================\n",
        "\"\"\"Model architectures for the demos.\"\"\"\n",
        "\n",
        "import sonnet as snt\n",
        "\n",
        "NUM_LAYERS = 2  # Hard-code number of layers in the edge/node/global models.\n",
        "LATENT_SIZE = 16  # Hard-code latent layer sizes for demos.\n",
        "\n",
        "\n",
        "def make_mlp_model():\n",
        "    \"\"\"Instantiates a new MLP, followed by LayerNorm.\n",
        "\n",
        "    The parameters of each new MLP are not shared with others generated by\n",
        "    this function.\n",
        "\n",
        "    Returns:\n",
        "        A Sonnet module which contains the MLP and LayerNorm.\n",
        "    \"\"\"\n",
        "    return snt.Sequential([\n",
        "            snt.nets.MLP([LATENT_SIZE] * NUM_LAYERS, activate_final=True),\n",
        "            snt.LayerNorm()\n",
        "    ])\n",
        "\n",
        "\n",
        "class MLPGraphIndependent(snt.AbstractModule):\n",
        "    \"\"\"GraphIndependent with MLP edge, node, and global models.\"\"\"\n",
        "\n",
        "    def __init__(self, name=\"MLPGraphIndependent\"):\n",
        "        super(MLPGraphIndependent, self).__init__(name=name)\n",
        "        with self._enter_variable_scope():\n",
        "            self._network = modules.GraphIndependent(\n",
        "                edge_model_fn=make_mlp_model,\n",
        "                node_model_fn=make_mlp_model,\n",
        "                global_model_fn=make_mlp_model\n",
        "            )\n",
        "\n",
        "    def _build(self, inputs):\n",
        "        return self._network(inputs)\n",
        "\n",
        "\n",
        "class MLPGraphNetwork(snt.AbstractModule):\n",
        "    \"\"\"GraphNetwork with MLP edge, node, and global models.\"\"\"\n",
        "\n",
        "    def __init__(self, name=\"MLPGraphNetwork\"):\n",
        "        super(MLPGraphNetwork, self).__init__(name=name)\n",
        "        with self._enter_variable_scope():\n",
        "            self._network = modules.GraphNetwork(make_mlp_model, make_mlp_model, make_mlp_model)\n",
        "\n",
        "    def _build(self, inputs):\n",
        "        return self._network(inputs)\n",
        "\n",
        "\n",
        "class EncodeProcessDecode(snt.AbstractModule):\n",
        "    \"\"\"Full encode-process-decode model.\n",
        "    The model we explore includes three components:\n",
        "    - An \"Encoder\" graph net, which independently encodes the edge, node, and\n",
        "        global attributes (does not compute relations etc.).\n",
        "    - A \"Core\" graph net, which performs N rounds of processing (message-passing)\n",
        "        steps. The input to the Core is the concatenation of the Encoder's output\n",
        "        and the previous output of the Core (labeled \"Hidden(t)\" below, where \"t\" is\n",
        "        the processing step).\n",
        "    - A \"Decoder\" graph net, which independently decodes the edge, node, and\n",
        "        global attributes (does not compute relations etc.), on each message-passing\n",
        "        step.\n",
        "\n",
        "                          Hidden(t)   Hidden(t+1)\n",
        "                             |            ^\n",
        "                *---------*  |  *------*  |  *---------*\n",
        "                |         |  |  |      |  |  |         |\n",
        "      Input --->| Encoder |  *->| Core |--*->| Decoder |---> Output(t)\n",
        "                |         |---->|      |     |         |\n",
        "                *---------*     *------*     *---------*\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        edge_output_size=None,\n",
        "        node_output_size=None,\n",
        "        global_output_size=None,\n",
        "        name=\"EncodeProcessDecode\"\n",
        "    ):\n",
        "        super(EncodeProcessDecode, self).__init__(name=name)\n",
        "        self._encoder = MLPGraphIndependent()\n",
        "        self._core = MLPGraphNetwork()\n",
        "        self._decoder = MLPGraphIndependent()\n",
        "        # Transforms the outputs into the appropriate shapes.\n",
        "        if edge_output_size is None:\n",
        "            edge_fn = None\n",
        "        else:\n",
        "            edge_fn = lambda: snt.Linear(edge_output_size, name=\"edge_output\")\n",
        "        if node_output_size is None:\n",
        "            node_fn = None\n",
        "        else:\n",
        "            node_fn = lambda: snt.Linear(node_output_size, name=\"node_output\")\n",
        "        if global_output_size is None:\n",
        "            global_fn = None\n",
        "        else:\n",
        "            global_fn = lambda: snt.Linear(global_output_size, name=\"global_output\")\n",
        "        with self._enter_variable_scope():\n",
        "            self._output_transform = modules.GraphIndependent(edge_fn, node_fn, global_fn)\n",
        "\n",
        "    def _build(self, input_op, num_processing_steps):\n",
        "        latent = self._encoder(input_op)\n",
        "        latent0 = latent\n",
        "        output_ops = []\n",
        "        for _ in range(num_processing_steps):\n",
        "            core_input = utils_tf.concat([latent0, latent], axis=1)\n",
        "            latent = self._core(core_input)\n",
        "            decoded_op = self._decoder(latent)\n",
        "            output_ops.append(self._output_transform(decoded_op))\n",
        "        return output_ops\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "cY09Bll0vuVj",
        "outputId": "d5cac95d-4c68-4442-a81a-1795265bcd2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "#@title Set up model training and evaluation  { form-width: \"30%\" }\n",
        "\n",
        "# The model we explore includes three components:\n",
        "# - An \"Encoder\" graph net, which independently encodes the edge, node, and\n",
        "#   global attributes (does not compute relations etc.).\n",
        "# - A \"Core\" graph net, which performs N rounds of processing (message-passing)\n",
        "#   steps. The input to the Core is the concatenation of the Encoder's output\n",
        "#   and the previous output of the Core (labeled \"Hidden(t)\" below, where \"t\" is\n",
        "#   the processing step).\n",
        "# - A \"Decoder\" graph net, which independently decodes the edge, node, and\n",
        "#   global attributes (does not compute relations etc.), on each\n",
        "#   message-passing step.\n",
        "#\n",
        "#                     Hidden(t)   Hidden(t+1)\n",
        "#                        |            ^\n",
        "#           *---------*  |  *------*  |  *---------*\n",
        "#           |         |  |  |      |  |  |         |\n",
        "# Input --->| Encoder |  *->| Core |--*->| Decoder |---> Output(t)\n",
        "#           |         |---->|      |     |         |\n",
        "#           *---------*     *------*     *---------*\n",
        "#\n",
        "# The model is trained by supervised learning. Input graphs are procedurally\n",
        "# generated, and output graphs have the same structure with the nodes and edges\n",
        "# of the shortest path labeled (using 2-element 1-hot vectors). We could have\n",
        "# predicted the shortest path only by labeling either the nodes or edges, and\n",
        "# that does work, but we decided to predict both to demonstrate the flexibility\n",
        "# of graph nets' outputs.\n",
        "#\n",
        "# The training loss is computed on the output of each processing step. The\n",
        "# reason for this is to encourage the model to try to solve the problem in as\n",
        "# few steps as possible. It also helps make the output of intermediate steps\n",
        "# more interpretable.\n",
        "#\n",
        "# There's no need for a separate evaluate dataset because the inputs are\n",
        "# never repeated, so the training loss is the measure of performance on graphs\n",
        "# from the input distribution.\n",
        "#\n",
        "# We also evaluate how well the models generalize to graphs which are up to\n",
        "# twice as large as those on which it was trained. The loss is computed only\n",
        "# on the final processing step.\n",
        "#\n",
        "# Variables with the suffix _tr are training parameters, and variables with the\n",
        "# suffix _ge are test/generalization parameters.\n",
        "#\n",
        "# After around 2000-5000 training iterations the model reaches near-perfect\n",
        "# performance on graphs with between 8-16 nodes.\n",
        "\n",
        "tf.reset_default_graph()\n",
        " \n",
        "rand = np.random.RandomState(seed=SEED)\n",
        "\n",
        "# Model parameters.\n",
        "# Number of processing (message-passing) steps.\n",
        "num_processing_steps_tr = 10\n",
        "num_processing_steps_ge = 10\n",
        "\n",
        "# Data / training parameters.\n",
        "num_training_iterations = 10000\n",
        "theta = 60  # Large values (1000+) make trees. Try 20-60 for good non-trees.\n",
        "batch_size_tr = 5\n",
        "batch_size_ge = 100\n",
        "# Number of nodes per graph sampled uniformly from this range.\n",
        "num_nodes_min_max_tr = (32, 65)\n",
        "num_nodes_min_max_ge = (64, 129)\n",
        "\n",
        "# Data.\n",
        "# Input and target placeholders.\n",
        "raw_graphs = generate_raw_graphs(rand, num_examples, num_nodes_min_max_tr, theta)\n",
        "input_ph, target_ph = create_placeholders(raw_graphs)\n",
        "\n",
        "# Connect the data to the model.\n",
        "# Instantiate the model.\n",
        "model = EncodeProcessDecode(edge_output_size=1, node_output_size=6)\n",
        "# A list of outputs, one per processing step.\n",
        "debug({\"input_ph\" : input_ph})\n",
        "output_ops_tr = model(input_ph, num_processing_steps_tr)\n",
        "output_ops_ge = model(input_ph, num_processing_steps_ge)\n",
        "\n",
        "# Training loss.\n",
        "loss_ops_tr = create_loss_ops(target_ph, output_ops_tr)\n",
        "# Loss across processing steps.\n",
        "loss_op_tr = sum(loss_ops_tr) / num_processing_steps_tr\n",
        "# Test/generalization loss.\n",
        "loss_ops_ge = create_loss_ops(target_ph, output_ops_ge)\n",
        "loss_op_ge = loss_ops_ge[-1]  # Loss from final processing step.\n",
        "\n",
        "# Optimizer.\n",
        "learning_rate = 1e-3\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "step_op = optimizer.minimize(loss_op_tr)\n",
        "\n",
        "# Lets an iterable of TF graphs be output from a session as NP graphs.\n",
        "input_ph, target_ph = make_all_runnable_in_session(input_ph, target_ph)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " {\n",
            "    \"input_ph\": [\n",
            "        {\n",
            "            \"name\": \"placeholders_from_networkxs/nodes:0\",\n",
            "            \"shape\": \"(?, 6)\",\n",
            "            \"dtype\": \"<dtype: 'float64'>\"\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"placeholders_from_networkxs/edges:0\",\n",
            "            \"shape\": \"(?, 1)\",\n",
            "            \"dtype\": \"<dtype: 'float64'>\"\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"placeholders_from_networkxs/receivers:0\",\n",
            "            \"shape\": \"(?,)\",\n",
            "            \"dtype\": \"<dtype: 'int32'>\"\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"placeholders_from_networkxs/senders:0\",\n",
            "            \"shape\": \"(?,)\",\n",
            "            \"dtype\": \"<dtype: 'int32'>\"\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"placeholders_from_networkxs/globals:0\",\n",
            "            \"shape\": \"(?, 1)\",\n",
            "            \"dtype\": \"<dtype: 'float64'>\"\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"placeholders_from_networkxs/n_node:0\",\n",
            "            \"shape\": \"(?,)\",\n",
            "            \"dtype\": \"<dtype: 'int32'>\"\n",
            "        },\n",
            "        {\n",
            "            \"name\": \"placeholders_from_networkxs/n_edge:0\",\n",
            "            \"shape\": \"(?,)\",\n",
            "            \"dtype\": \"<dtype: 'int32'>\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "WoVdyUTjvzWb",
        "colab": {}
      },
      "source": [
        "#@title Reset session  { form-width: \"10%\" }\n",
        "\n",
        "# This cell resets the Tensorflow session, but keeps the same computational\n",
        "# graph.\n",
        "\n",
        "try:\n",
        "    sess.close()\n",
        "except NameError:\n",
        "    pass\n",
        "\n",
        "\n",
        "saver = snt.get_saver(model)\n",
        "sess = tf.Session()\n",
        "\n",
        "\n",
        "#saver.restore(sess, \"./tmp/model.ckpt\")   \n",
        "\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "last_iteration = 0\n",
        "logged_iterations = []\n",
        "losses_tr = []\n",
        "corrects_tr = []\n",
        "solveds_tr = []\n",
        "losses_ge = []\n",
        "corrects_ge = []\n",
        "solveds_ge = []\n",
        "\n",
        "losses_ge_permuted = []\n",
        "corrects_ge_permuted = []\n",
        "solveds_ge_permuted = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "RYpOzxD2gCPk",
        "colab": {}
      },
      "source": [
        "#@title Helper functions for training { form-width: \"30%\" }\n",
        "\n",
        "# pylint: disable=redefined-outer-name\n",
        "def create_feed_dict(sources, targets,source_ph,target_ph):\n",
        "    \"\"\"Creates placeholders for the model training and evaluation.\n",
        "\n",
        "    Args:\n",
        "        rand: A random seed (np.RandomState instance).\n",
        "        batch_size: Total number of graphs per batch.\n",
        "        min_max_nodes: A 2-tuple with the [lower, upper) number of nodes per\n",
        "            graph. The number of nodes for a graph is uniformly sampled within this\n",
        "            range.\n",
        "        geo_density: A `float` threshold parameters for the geographic threshold graph's\n",
        "            threshold. Default= the number of nodes.\n",
        "        source_ph: The source graph's placeholders, as a graph namedtuple.\n",
        "        target_ph: The target graph's placeholders, as a graph namedtuple.\n",
        "\n",
        "    Returns:\n",
        "        feed_dict: The feed `dict` of source and target placeholders and data.\n",
        "    \"\"\"\n",
        "    source_graphs = utils_np.networkxs_to_graphs_tuple(sources)\n",
        "    target_graphs = utils_np.networkxs_to_graphs_tuple(targets)\n",
        "    feed_dict = {source_ph: source_graphs, target_ph: target_graphs}\n",
        "    return feed_dict\n",
        "\n",
        "def compute_accuracy(target, output, use_nodes=False, use_edges=True):\n",
        "    \"\"\"Calculate model accuracy.\n",
        "\n",
        "    Returns the number of correctly predicted shortest path nodes and the number\n",
        "    of completely solved graphs (100% correct predictions).\n",
        "\n",
        "    Args:\n",
        "        target: A `graphs.GraphsTuple` that contains the target graph.\n",
        "        output: A `graphs.GraphsTuple` that contains the output graph.\n",
        "        use_nodes: A `bool` indicator of whether to compute node accuracy or not.\n",
        "        use_edges: A `bool` indicator of whether to compute edge accuracy or not.\n",
        "\n",
        "    Returns:\n",
        "        correct: A `float` fraction of correctly labeled nodes/edges.\n",
        "        solved: A `float` fraction of graphs that are completely correctly labeled.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: Nodes or edges (or both) must be used\n",
        "    \"\"\"\n",
        "    if not use_nodes and not use_edges:\n",
        "        raise ValueError(\"Nodes or edges (or both) must be used\")\n",
        "    tdds = utils_np.graphs_tuple_to_data_dicts(target)\n",
        "    odds = utils_np.graphs_tuple_to_data_dicts(output)\n",
        "    cs = []\n",
        "    ss = []\n",
        "    for td, od in zip(tdds, odds):\n",
        "        xn = np.argmax(td[\"nodes\"], axis=-1)\n",
        "        yn = np.argmax(od[\"nodes\"], axis=-1)\n",
        "        xe = np.argmax(td[\"edges\"], axis=-1)\n",
        "        ye = np.argmax(od[\"edges\"], axis=-1)\n",
        "        c = []\n",
        "        if use_nodes:\n",
        "            c.append(xn == yn)\n",
        "        if use_edges:\n",
        "            c.append(xe == ye)\n",
        "        c = np.concatenate(c, axis=0)\n",
        "        s = np.all(c)\n",
        "        cs.append(c)\n",
        "        ss.append(s)\n",
        "    correct = np.mean(np.concatenate(cs, axis=0))\n",
        "    solved = np.mean(np.stack(ss))\n",
        "    return correct, solved"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "wWSqSYyQv0Ur",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "4f4cbb1a-f1f9-4a5b-9c30-9e27f2a95b78"
      },
      "source": [
        "#@title Run training  { form-width: \"10%\" }\n",
        "\n",
        "# You can interrupt this cell's training loop at any time, and visualize the\n",
        "# intermediate results by running the next cell (below). You can then resume\n",
        "# training by simply executing this cell again.\n",
        "\n",
        "PERMUTE_GRAPHS = True\n",
        "\n",
        "# How much time between logging and printing the current results.\n",
        "log_every_seconds = 20\n",
        "\n",
        "var_names = [\n",
        "    \"iteration number\",\n",
        "    \"elapsed seconds\",\n",
        "    \"training loss\",\n",
        "    \"training fraction mse\",\n",
        "    \"training fraction examples solved correctly\",\n",
        "]\n",
        "var_names += [\n",
        "    \"test/generalization loss\",\n",
        "    \"test/generalization mse\",\n",
        "    \"test/generalization fraction examples solved correctly\"\n",
        "]\n",
        "\n",
        "if PERMUTE_GRAPHS:\n",
        "    var_names += [\n",
        "        \"test/generalization loss with permutations\",\n",
        "        \"test/generalization mse with permutations\",\n",
        "        \"test/generalization fraction examples solved correctly with permutations\"\n",
        "    ]\n",
        "\n",
        "print(\"\\t\".join(var_names))\n",
        "\n",
        "labels = [\n",
        "    \"#\",\n",
        "    \"T\",\n",
        "    \"Ltr\",\n",
        "    \"Ctr\",\n",
        "    \"Str\",\n",
        "]\n",
        "labels += [\n",
        "    \"Lge\",\n",
        "    \"Cge\",\n",
        "    \"Sge\"\n",
        "]\n",
        "if PERMUTE_GRAPHS:\n",
        "    labels += [\n",
        "        \"Lpe\",\n",
        "        \"Cpe\",\n",
        "        \"Spe\"\n",
        "    ]\n",
        "\n",
        "print(\"\\t\".join(labels))\n",
        "\n",
        "start_time = time.time()\n",
        "last_log_time = start_time\n",
        "for iteration in range(last_iteration, num_training_iterations):\n",
        "    last_iteration = iteration\n",
        "    #Check if it`s time to repeat the dataset\n",
        "    if iteration % 1000 == 0:\n",
        "        np.random.seed(SEED)\n",
        "        tf.set_random_seed(SEED)\n",
        "    \n",
        "    raw_graphs = generate_raw_graphs(rand, num_examples, num_nodes_min_max_tr, theta)\n",
        "    sources, targets = generate_networkx_graphs(raw_graphs)\n",
        "    feed_dict = create_feed_dict(sources, targets, input_ph, target_ph)\n",
        "    train_values = sess.run({\n",
        "            \"step\": step_op,\n",
        "            \"target\": target_ph,\n",
        "            \"loss\": loss_op_tr,\n",
        "            \"outputs\": output_ops_tr\n",
        "        },\n",
        "        feed_dict=feed_dict\n",
        "    )\n",
        "    \n",
        "    correct_tr, solved_tr = compute_accuracy(\n",
        "        train_values[\"target\"],\n",
        "        train_values[\"outputs\"][-1],\n",
        "        use_edges=True\n",
        "    )\n",
        "    losses_tr.append(train_values[\"loss\"])\n",
        "    corrects_tr.append(correct_tr)\n",
        "    solveds_tr.append(solved_tr)\n",
        "\n",
        "    the_time = time.time()\n",
        "    elapsed_since_last_log = the_time - last_log_time\n",
        "    if True: #elapsed_since_last_log > log_every_seconds:\n",
        "        save_path = saver.save(sess, \"./tmp/model.ckpt\")\n",
        "        last_log_time = the_time\n",
        "        \n",
        "        raw_graphs_test = generate_raw_graphs(rand, num_examples, num_nodes_min_max_ge, theta)\n",
        "        \n",
        "        #Permute raw_graphs\n",
        "        if PERMUTE_GRAPHS:\n",
        "            raw_graphs_permutation = [\n",
        "                nx.relabel_nodes(graph, mapping={i: p for i,p in enumerate(np.random.permutation(len(graph)))}) \n",
        "                for graph in raw_graphs_test\n",
        "            ]\n",
        "        \n",
        "            sources_permutation, targets_permutation = generate_networkx_graphs(raw_graphs_permutation)\n",
        "            input_ph_permutation, target_ph_permutation = create_placeholders(raw_graphs_permutation)\n",
        "\n",
        "            # A list of outputs, one per processing step.\n",
        "            output_ops_ge_permutation = model(input_ph_permutation, num_processing_steps_ge)\n",
        "\n",
        "            # Test/generalization loss.\n",
        "            loss_ops_ge_permutation = create_loss_ops(target_ph_permutation, output_ops_ge_permutation)\n",
        "            loss_op_ge_permutation = loss_ops_ge_permutation[-1]  # Loss from final processing step.\n",
        "\n",
        "            # Lets an iterable of TF graphs be output from a session as NP graphs.\n",
        "            input_ph_permutation, target_ph_permutation = make_all_runnable_in_session(input_ph_permutation, target_ph_permutation)\n",
        "\n",
        "            feed_dict_permutation = create_feed_dict(sources_permutation, targets_permutation, input_ph_permutation, target_ph_permutation)\n",
        "            \n",
        "            test_values_permutation = sess.run(\n",
        "                {\n",
        "                    \"target_permutation\": target_ph_permutation,\n",
        "                    \"loss_permutation\": loss_op_ge_permutation,\n",
        "                    \"outputs_permutation\": output_ops_ge_permutation\n",
        "                },\n",
        "                feed_dict=feed_dict_permutation\n",
        "            )\n",
        "            correct_ge_permutation, solved_ge_permutation = compute_accuracy(\n",
        "                test_values_permutation[\"target_permutation\"],\n",
        "                test_values_permutation[\"outputs_permutation\"][-1],\n",
        "                use_edges=True\n",
        "            )\n",
        "            losses_ge.append(test_values_permutation[\"loss_permutation\"])\n",
        "            corrects_ge.append(correct_ge_permutation)\n",
        "            solveds_ge.append(solved_ge_permutation)\n",
        "        \n",
        "        sources_test, targets_test = generate_networkx_graphs(raw_graphs_test)\n",
        "        input_ph_test, target_ph_test = create_placeholders(raw_graphs_test)\n",
        "\n",
        "        # A list of outputs, one per processing step.\n",
        "        output_ops_ge_test = model(input_ph_test, num_processing_steps_ge)\n",
        "\n",
        "        # Test/generalization loss.\n",
        "        loss_ops_ge_test = create_loss_ops(target_ph_test, output_ops_ge_test)\n",
        "        loss_op_ge_test = loss_ops_ge_test[-1]  # Loss from final processing step.\n",
        "\n",
        "        # Lets an iterable of TF graphs be output from a session as NP graphs.\n",
        "        input_ph_test, target_ph_test = make_all_runnable_in_session(input_ph_test, target_ph_test)\n",
        "\n",
        "        feed_dict_test = create_feed_dict(sources_test, targets_test, input_ph_test, target_ph_test)\n",
        "        \n",
        "        test_values_test = sess.run(\n",
        "            {\n",
        "                \"target_test\": target_ph_test,\n",
        "                \"loss_test\": loss_op_ge_test,\n",
        "                \"outputs_test\": output_ops_ge_test\n",
        "            },\n",
        "            feed_dict=feed_dict_test\n",
        "        )\n",
        "        correct_ge_test, solved_ge_test = compute_accuracy(\n",
        "            test_values_test[\"target_test\"],\n",
        "            test_values_test[\"outputs_test\"][-1],\n",
        "            use_edges=True\n",
        "        )\n",
        "        losses_ge.append(test_values_test[\"loss_test\"])\n",
        "        corrects_ge.append(correct_ge_test)\n",
        "        solveds_ge.append(solved_ge_test)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "\n",
        "        logged_iterations.append(iteration)\n",
        "        row = [\n",
        "            iteration, \n",
        "            elapsed, \n",
        "            train_values[\"loss\"], \n",
        "            correct_tr, \n",
        "            solved_tr, \n",
        "        ]\n",
        "        row += [\n",
        "            test_values_test[\"loss_test\"],\n",
        "            correct_ge_test, \n",
        "            solved_ge_test\n",
        "        ]\n",
        "\n",
        "        if PERMUTE_GRAPHS:\n",
        "            row += [\n",
        "                test_values_permutation[\"loss_permutation\"],\n",
        "                correct_ge_permutation, \n",
        "                solved_ge_permutation\n",
        "            ]\n",
        "            \n",
        "        print(\"\\t\".join([str(e) for e in row]))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration number\telapsed seconds\ttraining loss\ttraining fraction mse\ttraining fraction examples solved correctly\ttest/generalization loss\ttest/generalization mse\ttest/generalization fraction examples solved correctly\ttest/generalization loss with permutations\ttest/generalization mse with permutations\ttest/generalization fraction examples solved correctly with permutations\n",
            "#\tT\tLtr\tCtr\tStr\tLge\tCge\tSge\tLpe\tCpe\tSpe\n",
            "0\t28.592331409454346\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "1\t48.99594259262085\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "2\t73.6691026687622\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "3\t97.67172479629517\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "4\t123.0580644607544\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "5\t149.8927345275879\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "6\t176.76705074310303\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "7\t203.36411714553833\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "8\t233.06842136383057\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "9\t263.11166977882385\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "10\t292.97213673591614\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "11\t325.80691480636597\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "12\t361.7055015563965\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "13\t395.6540307998657\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "14\t433.9036898612976\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "15\t471.28014039993286\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "16\t509.72529554367065\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "17\t551.5611522197723\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "18\t592.4017972946167\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "19\t635.0884146690369\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "20\t682.5295784473419\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "21\t729.339284658432\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "22\t777.3488335609436\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n",
            "23\t826.7361946105957\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\t0.0\t1.0\t1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "u0ckrMtj72s-",
        "colab": {}
      },
      "source": [
        "#@title Visualize results  { form-width: \"30%\" }\n",
        "\n",
        "# This cell visualizes the results of training. You can visualize the\n",
        "# intermediate results by interrupting execution of the cell above, and running\n",
        "# this cell. You can then resume training by simply executing the above cell\n",
        "# again.\n",
        "\n",
        "def softmax_prob_last_dim(x):  # pylint: disable=redefined-outer-name\n",
        "    e = np.exp(x)\n",
        "    return e[:, -1] / np.sum(e, axis=-1)\n",
        "\n",
        "\n",
        "# Plot results curves.\n",
        "fig = plt.figure(1, figsize=(18, 3))\n",
        "fig.clf()\n",
        "x = np.array(logged_iterations)\n",
        "# Loss.\n",
        "y_tr = losses_tr\n",
        "y_ge = losses_ge\n",
        "ax = fig.add_subplot(1, 3, 1)\n",
        "ax.plot(x, y_tr, \"k\", label=\"Training\")\n",
        "ax.plot(x, y_ge, \"k--\", label=\"Test/generalization\")\n",
        "ax.set_title(\"Loss across training\")\n",
        "ax.set_xlabel(\"Training iteration\")\n",
        "ax.set_ylabel(\"Loss (binary cross-entropy)\")\n",
        "ax.legend()\n",
        "# Correct.\n",
        "y_tr = corrects_tr\n",
        "y_ge = corrects_ge\n",
        "ax = fig.add_subplot(1, 3, 2)\n",
        "ax.plot(x, y_tr, \"k\", label=\"Training\")\n",
        "ax.plot(x, y_ge, \"k--\", label=\"Test/generalization\")\n",
        "ax.set_title(\"Fraction correct across training\")\n",
        "ax.set_xlabel(\"Training iteration\")\n",
        "ax.set_ylabel(\"Fraction nodes/edges correct\")\n",
        "# Solved.\n",
        "y_tr = solveds_tr\n",
        "y_ge = solveds_ge\n",
        "ax = fig.add_subplot(1, 3, 3)\n",
        "ax.plot(x, y_tr, \"k\", label=\"Training\")\n",
        "ax.plot(x, y_ge, \"k--\", label=\"Test/generalization\")\n",
        "ax.set_title(\"Fraction solved across training\")\n",
        "ax.set_xlabel(\"Training iteration\")\n",
        "ax.set_ylabel(\"Fraction examples solved\")\n",
        "\n",
        "# Plot graphs and results after each processing step.\n",
        "# The white node is the start, and the black is the end. Other nodes are colored\n",
        "# from red to purple to blue, where red means the model is confident the node is\n",
        "# off the shortest path, blue means the model is confident the node is on the\n",
        "# shortest path, and purplish colors mean the model isn't sure.\n",
        "max_graphs_to_plot = 8 #@param{type:\"slider\", min:4, max:8, step:1}\n",
        "num_steps_to_plot = 4 #@param{type:\"slider\", min:1, max:8, step:1}\n",
        "node_size = 120 #@param{type:\"slider\", min:64, max:2048, step:1}\n",
        "min_c = 0.3\n",
        "num_graphs = len(raw_graphs)\n",
        "targets = utils_np.graphs_tuple_to_data_dicts(test_values[\"target\"])\n",
        "step_indices = np.floor(\n",
        "    np.linspace(\n",
        "        0, num_processing_steps_ge - 1,\n",
        "        num_steps_to_plot\n",
        "    )\n",
        ").astype(int).tolist()\n",
        "\n",
        "outputs = list(zip(*(\n",
        "    utils_np.graphs_tuple_to_data_dicts(test_values[\"outputs\"][i])\n",
        "    for i in step_indices\n",
        ")))\n",
        "h = min(num_graphs, max_graphs_to_plot)\n",
        "w = num_steps_to_plot + 1\n",
        "fig = plt.figure(101, figsize=(18, h * 3))\n",
        "fig.clf()\n",
        "ncs = []\n",
        "for j, (graph, target, output) in enumerate(zip(raw_graphs, targets, outputs)):\n",
        "    if j >= h:\n",
        "        break\n",
        "    ground_truth = target[\"nodes\"][:, -1]\n",
        "    # Ground truth.\n",
        "    iax = j * (1 + num_steps_to_plot) + 1\n",
        "    ax = fig.add_subplot(h, w, iax)\n",
        "    plotter = GraphPlotter(ax, graph)\n",
        "    color = {}\n",
        "    for i, n in enumerate(plotter.nodes):\n",
        "        color[n] = np.array(\n",
        "            [1.0 - ground_truth[i], 0.0, ground_truth[i], 1.0]\n",
        "        ) * (1.0 - min_c) + min_c\n",
        "    plotter.draw_graph_with_solution(node_size=node_size, node_color=color)\n",
        "    ax.set_axis_on()\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    try:\n",
        "        ax.set_facecolor([0.9] * 3 + [1.0])\n",
        "    except AttributeError:\n",
        "        ax.set_axis_bgcolor([0.9] * 3 + [1.0])\n",
        "    ax.grid(None)\n",
        "    ax.set_title(\n",
        "        \"Ground truth\\nSolution length: {}\"\n",
        "            .format(plotter.solution_length)\n",
        "    )\n",
        "    # Prediction.\n",
        "    for k, outp in enumerate(output):\n",
        "        iax = j * (1 + num_steps_to_plot) + 2 + k\n",
        "        ax = fig.add_subplot(h, w, iax)\n",
        "        plotter = GraphPlotter(ax, graph)\n",
        "        color = {}\n",
        "        prob = softmax_prob_last_dim(outp[\"nodes\"])\n",
        "        for i, n in enumerate(plotter.nodes):\n",
        "            color[n] = np.array(\n",
        "                [1.0 - prob[n], 0.0, prob[n], 1.0]\n",
        "            ) * (1.0 - min_c) + min_c\n",
        "        plotter.draw_graph_with_solution(node_size=node_size, node_color=color)\n",
        "        ax.set_title(\n",
        "            \"Model-predicted\\nStep {:02d} / {:02d}\".format(\n",
        "                step_indices[k] + 1,\n",
        "                step_indices[-1] + 1\n",
        "            )\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}