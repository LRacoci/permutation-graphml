{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "physics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "k2QMetc6kava",
        "colab": {}
      },
      "source": [
        "#@title ##### License\n",
        "# Copyright 2018 The GraphNets Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#    http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ============================================================================"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c5CPvyHM2CnU"
      },
      "source": [
        "# Physical dynamics of a mass-spring system\n",
        "This notebook and the accompanying code demonstrates how to use the Graph Nets library to learn to predict the motion of a set of masses connected by springs.\n",
        "\n",
        "The network is trained to predict the behaviour of a chain of five masses, connected by identical springs. The first and last masses are fixed; the others are subject to gravity.\n",
        "\n",
        "After training, the network's prediction ability is illustrated by comparing its output to the true behaviour of the structure. Then the network's ability to generalise is tested, by using it to predict the behaviour of a similar but more complicated mass/spring structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "Ss54UNGvkz5M",
        "outputId": "c3ffa485-6c2a-4577-ca27-b579e260c3d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title ### Install the Graph Nets library on this Colaboratory runtime  { form-width: \"60%\", run: \"auto\"}\n",
        "#@markdown <br>1. Connect to a local or hosted Colaboratory runtime by clicking the **Connect** button at the top-right.<br>2. Choose \"Yes\" below to install the Graph Nets library on the runtime machine with:<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;```pip install graph_nets```<br> Note, this works both with local and hosted Colaboratory runtimes.\n",
        "\n",
        "install_graph_nets_library = \"No\"  #@param [\"Yes\", \"No\"]\n",
        "\n",
        "if install_graph_nets_library.lower() == \"yes\":\n",
        "  print(\"Installing Graph Nets library with:\")\n",
        "  print(\"  $ pip install graph_nets\\n\")\n",
        "  print(\"Output message from command:\\n\")\n",
        "  !pip install graph_nets\n",
        "else:\n",
        "  print(\"Skipping installation of Graph Nets library\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping installation of Graph Nets library\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7E4elJkXFR4a"
      },
      "source": [
        "### Install dependencies locally\n",
        "\n",
        "If you are running this notebook locally (i.e., not through Colaboratory), you will also need to install a few more dependencies. Run the following on the command line to install the graph networks library, as well as a few other dependencies:\n",
        "\n",
        "```\n",
        "pip install graph_nets matplotlib scipy\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hyVaNA-bGug3"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "RzKvtoAgRA8e",
        "colab": {}
      },
      "source": [
        "#@title Imports  { form-width: \"30%\" }\n",
        "\n",
        "# The demo dependencies are not installed with the library, but you can install\n",
        "# them with:\n",
        "#\n",
        "# $ pip install jupyter matplotlib scipy\n",
        "#\n",
        "# Run the demo with:\n",
        "#\n",
        "# $ jupyter notebook <path>/<to>/<demos>/shortest_path.ipynb\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import time\n",
        "\n",
        "from graph_nets import blocks\n",
        "from graph_nets import utils_tf\n",
        "from graph_nets import utils_np\n",
        "from graph_nets.demos import models\n",
        "from graph_nets import graphs\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import sonnet as snt\n",
        "import tensorflow as tf\n",
        "\n",
        "try:\n",
        "  import seaborn as sns\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  sns.reset_orig()\n",
        "\n",
        "SEED = 1\n",
        "np.random.seed(SEED)\n",
        "tf.set_random_seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "toCQhJIM93en",
        "colab": {}
      },
      "source": [
        "#@title Helper functions  { form-width: \"30%\" }\n",
        "\n",
        "# pylint: disable=redefined-outer-name\n",
        "\n",
        "def base_graph(n, d):\n",
        "  \"\"\"Define a basic mass-spring system graph structure.\n",
        "\n",
        "  These are n masses (1kg) connected by springs in a chain-like structure. The\n",
        "  first and last masses are fixed. The masses are vertically aligned at the\n",
        "  start and are d meters apart; this is also the rest length for the springs\n",
        "  connecting them. Springs have spring constant 50 N/m and gravity is 10 N in\n",
        "  the negative y-direction.\n",
        "\n",
        "  Args:\n",
        "    n: number of masses\n",
        "    d: distance between masses (as well as springs' rest length)\n",
        "\n",
        "  Returns:\n",
        "    data_dict: dictionary with globals, nodes, edges, receivers and senders\n",
        "        to represent a structure like the one above.\n",
        "  \"\"\"\n",
        "  # Nodes\n",
        "  # Generate initial position and velocity for all masses.\n",
        "  # The left-most mass has is at position (0, 0); other masses (ordered left to\n",
        "  # right) have x-coordinate d meters apart from their left neighbor, and\n",
        "  # y-coordinate 0. All masses have initial velocity 0m/s.\n",
        "  nodes = np.zeros((n, 5), dtype=np.float32)\n",
        "  half_width = d * n / 2.0\n",
        "  nodes[:, 0] = np.linspace(\n",
        "      -half_width, half_width, num=n, endpoint=False, dtype=np.float32)\n",
        "  # indicate that the first and last masses are fixed\n",
        "  nodes[(0, -1), -1] = 1.\n",
        "\n",
        "  # Edges.\n",
        "  edges, senders, receivers = [], [], []\n",
        "  for i in range(n - 1):\n",
        "    left_node = i\n",
        "    right_node = i + 1\n",
        "    # The 'if' statements prevent incoming edges to fixed ends of the string.\n",
        "    if right_node < n - 1:\n",
        "      # Left incoming edge.\n",
        "      edges.append([50., d])\n",
        "      senders.append(left_node)\n",
        "      receivers.append(right_node)\n",
        "    if left_node > 0:\n",
        "      # Right incoming edge.\n",
        "      edges.append([50., d])\n",
        "      senders.append(right_node)\n",
        "      receivers.append(left_node)\n",
        "\n",
        "  return {\n",
        "      \"globals\": [0., -10.],\n",
        "      \"nodes\": nodes,\n",
        "      \"edges\": edges,\n",
        "      \"receivers\": receivers,\n",
        "      \"senders\": senders\n",
        "  }\n",
        "\n",
        "\n",
        "def hookes_law(receiver_nodes, sender_nodes, k, x_rest):\n",
        "  \"\"\"Applies Hooke's law to springs connecting some nodes.\n",
        "\n",
        "  Args:\n",
        "    receiver_nodes: Ex5 tf.Tensor of [x, y, v_x, v_y, is_fixed] features for the\n",
        "      receiver node of each edge.\n",
        "    sender_nodes: Ex5 tf.Tensor of [x, y, v_x, v_y, is_fixed] features for the\n",
        "      sender node of each edge.\n",
        "    k: Spring constant for each edge.\n",
        "    x_rest: Rest length of each edge.\n",
        "\n",
        "  Returns:\n",
        "    Nx2 Tensor of the force [f_x, f_y] acting on each edge.\n",
        "  \"\"\"\n",
        "  diff = receiver_nodes[..., 0:2] - sender_nodes[..., 0:2]\n",
        "  x = tf.norm(diff, axis=-1, keepdims=True)\n",
        "  force_magnitude = -1 * tf.multiply(k, (x - x_rest) / x)\n",
        "  force = force_magnitude * diff\n",
        "  return force\n",
        "\n",
        "\n",
        "def euler_integration(nodes, force_per_node, step_size):\n",
        "  \"\"\"Applies one step of Euler integration.\n",
        "\n",
        "  Args:\n",
        "    nodes: Ex5 tf.Tensor of [x, y, v_x, v_y, is_fixed] features for each node.\n",
        "    force_per_node: Ex2 tf.Tensor of the force [f_x, f_y] acting on each edge.\n",
        "    step_size: Scalar.\n",
        "\n",
        "  Returns:\n",
        "    A tf.Tensor of the same shape as `nodes` but with positions and velocities\n",
        "        updated.\n",
        "  \"\"\"\n",
        "  is_fixed = nodes[..., 4:5]\n",
        "  # set forces to zero for fixed nodes\n",
        "  force_per_node *= 1 - is_fixed\n",
        "  new_vel = nodes[..., 2:4] + force_per_node * step_size\n",
        "  return new_vel\n",
        "\n",
        "\n",
        "class SpringMassSimulator(snt.AbstractModule):\n",
        "  \"\"\"Implements a basic Physics Simulator using the blocks library.\"\"\"\n",
        "\n",
        "  def __init__(self, step_size, name=\"SpringMassSimulator\"):\n",
        "    super(SpringMassSimulator, self).__init__(name=name)\n",
        "    self._step_size = step_size\n",
        "\n",
        "    with self._enter_variable_scope():\n",
        "      self._aggregator = blocks.ReceivedEdgesToNodesAggregator(\n",
        "          reducer=tf.unsorted_segment_sum)\n",
        "\n",
        "  def _build(self, graph):\n",
        "    \"\"\"Builds a SpringMassSimulator.\n",
        "\n",
        "    Args:\n",
        "      graph: A graphs.GraphsTuple having, for some integers N, E, G:\n",
        "          - edges: Nx2 tf.Tensor of [spring_constant, rest_length] for each\n",
        "            edge.\n",
        "          - nodes: Ex5 tf.Tensor of [x, y, v_x, v_y, is_fixed] features for each\n",
        "            node.\n",
        "          - globals: Gx2 tf.Tensor containing the gravitational constant.\n",
        "\n",
        "    Returns:\n",
        "      A graphs.GraphsTuple of the same shape as `graph`, but where:\n",
        "          - edges: Holds the force [f_x, f_y] acting on each edge.\n",
        "          - nodes: Holds positions and velocities after applying one step of\n",
        "              Euler integration.\n",
        "    \"\"\"\n",
        "    receiver_nodes = blocks.broadcast_receiver_nodes_to_edges(graph)\n",
        "    sender_nodes = blocks.broadcast_sender_nodes_to_edges(graph)\n",
        "\n",
        "    spring_force_per_edge = hookes_law(receiver_nodes, sender_nodes,\n",
        "                                       graph.edges[..., 0:1],\n",
        "                                       graph.edges[..., 1:2])\n",
        "    graph = graph.replace(edges=spring_force_per_edge)\n",
        "\n",
        "    spring_force_per_node = self._aggregator(graph)\n",
        "    gravity = blocks.broadcast_globals_to_nodes(graph)\n",
        "    updated_velocities = euler_integration(\n",
        "        graph.nodes, spring_force_per_node + gravity, self._step_size)\n",
        "    graph = graph.replace(nodes=updated_velocities)\n",
        "    return graph\n",
        "\n",
        "\n",
        "def prediction_to_next_state(input_graph, predicted_graph, step_size):\n",
        "  # manually integrate velocities to compute new positions\n",
        "  new_pos = input_graph.nodes[..., :2] + predicted_graph.nodes * step_size\n",
        "  new_nodes = tf.concat(\n",
        "      [new_pos, predicted_graph.nodes, input_graph.nodes[..., 4:5]], axis=-1)\n",
        "  return input_graph.replace(nodes=new_nodes)\n",
        "\n",
        "\n",
        "def roll_out_physics(simulator, graph, steps, step_size):\n",
        "  \"\"\"Apply some number of steps of physical laws to an interaction network.\n",
        "\n",
        "  Args:\n",
        "    simulator: A SpringMassSimulator, or some module or callable with the same\n",
        "      signature.\n",
        "    graph: A graphs.GraphsTuple having, for some integers N, E, G:\n",
        "        - edges: Nx2 tf.Tensor of [spring_constant, rest_length] for each edge.\n",
        "        - nodes: Ex5 tf.Tensor of [x, y, v_x, v_y, is_fixed] features for each\n",
        "          node.\n",
        "        - globals: Gx2 tf.Tensor containing the gravitational constant.\n",
        "    steps: An integer.\n",
        "    step_size: Scalar.\n",
        "\n",
        "  Returns:\n",
        "    A pair of:\n",
        "    - The graph, updated after `steps` steps of simulation;\n",
        "    - A `steps+1`xNx5 tf.Tensor of the node features at each step.\n",
        "  \"\"\"\n",
        "\n",
        "  def body(t, graph, nodes_per_step):\n",
        "    predicted_graph = simulator(graph)\n",
        "    if isinstance(predicted_graph, list):\n",
        "      predicted_graph = predicted_graph[-1]\n",
        "    graph = prediction_to_next_state(graph, predicted_graph, step_size)\n",
        "    return t + 1, graph, nodes_per_step.write(t, graph.nodes)\n",
        "\n",
        "  nodes_per_step = tf.TensorArray(\n",
        "      dtype=graph.nodes.dtype, size=steps + 1, element_shape=graph.nodes.shape)\n",
        "  nodes_per_step = nodes_per_step.write(0, graph.nodes)\n",
        "\n",
        "  _, g, nodes_per_step = tf.while_loop(\n",
        "      lambda t, *unused_args: t <= steps,\n",
        "      body,\n",
        "      loop_vars=[1, graph, nodes_per_step])\n",
        "  return g, nodes_per_step.stack()\n",
        "\n",
        "\n",
        "def apply_noise(graph, node_noise_level, edge_noise_level, global_noise_level):\n",
        "  \"\"\"Applies uniformly-distributed noise to a graph of a physical system.\n",
        "\n",
        "  Noise is applied to:\n",
        "  - the x and y coordinates (independently) of the nodes;\n",
        "  - the spring constants of the edges;\n",
        "  - the y coordinate of the global gravitational constant.\n",
        "\n",
        "  Args:\n",
        "    graph: a graphs.GraphsTuple having, for some integers N, E, G:\n",
        "        - nodes: Nx5 Tensor of [x, y, _, _, _] for each node.\n",
        "        - edges: Ex2 Tensor of [spring_constant, _] for each edge.\n",
        "        - globals: Gx2 tf.Tensor containing the gravitational constant.\n",
        "    node_noise_level: Maximum distance to perturb nodes' x and y coordinates.\n",
        "    edge_noise_level: Maximum amount to perturb edge spring constants.\n",
        "    global_noise_level: Maximum amount to perturb the Y component of gravity.\n",
        "  Returns:\n",
        "    The input graph, but with noise applied.\n",
        "  \"\"\"\n",
        "  node_position_noise = tf.random_uniform(\n",
        "      [graph.nodes.shape[0].value, 2],\n",
        "      minval=-node_noise_level,\n",
        "      maxval=node_noise_level)\n",
        "  edge_spring_constant_noise = tf.random_uniform(\n",
        "      [graph.edges.shape[0].value, 1],\n",
        "      minval=-edge_noise_level,\n",
        "      maxval=edge_noise_level)\n",
        "  global_gravity_y_noise = tf.random_uniform(\n",
        "      [graph.globals.shape[0].value, 1],\n",
        "      minval=-global_noise_level,\n",
        "      maxval=global_noise_level)\n",
        "\n",
        "  return graph.replace(\n",
        "      nodes=tf.concat(\n",
        "          [graph.nodes[..., :2] + node_position_noise, graph.nodes[..., 2:]],\n",
        "          axis=-1),\n",
        "      edges=tf.concat(\n",
        "          [\n",
        "              graph.edges[..., :1] + edge_spring_constant_noise,\n",
        "              graph.edges[..., 1:]\n",
        "          ],\n",
        "          axis=-1),\n",
        "      globals=tf.concat(\n",
        "          [\n",
        "              graph.globals[..., :1],\n",
        "              graph.globals[..., 1:] + global_gravity_y_noise\n",
        "          ],\n",
        "          axis=-1))\n",
        "\n",
        "\n",
        "def set_rest_lengths(graph):\n",
        "  \"\"\"Computes and sets rest lengths for the springs in a physical system.\n",
        "\n",
        "  The rest length is taken to be the distance between each edge's nodes.\n",
        "\n",
        "  Args:\n",
        "    graph: a graphs.GraphsTuple having, for some integers N, E:\n",
        "        - nodes: Nx5 Tensor of [x, y, _, _, _] for each node.\n",
        "        - edges: Ex2 Tensor of [spring_constant, _] for each edge.\n",
        "\n",
        "  Returns:\n",
        "    The input graph, but with [spring_constant, rest_length] for each edge.\n",
        "  \"\"\"\n",
        "  receiver_nodes = blocks.broadcast_receiver_nodes_to_edges(graph)\n",
        "  sender_nodes = blocks.broadcast_sender_nodes_to_edges(graph)\n",
        "  rest_length = tf.norm(\n",
        "      receiver_nodes[..., :2] - sender_nodes[..., :2], axis=-1, keepdims=True)\n",
        "  return graph.replace(\n",
        "      edges=tf.concat([graph.edges[..., :1], rest_length], axis=-1))\n",
        "\n",
        "\n",
        "def generate_trajectory(simulator, graph, steps, step_size, node_noise_level,\n",
        "                        edge_noise_level, global_noise_level):\n",
        "  \"\"\"Applies noise and then simulates a physical system for a number of steps.\n",
        "\n",
        "  Args:\n",
        "    simulator: A SpringMassSimulator, or some module or callable with the same\n",
        "      signature.\n",
        "    graph: a graphs.GraphsTuple having, for some integers N, E, G:\n",
        "        - nodes: Nx5 Tensor of [x, y, v_x, v_y, is_fixed] for each node.\n",
        "        - edges: Ex2 Tensor of [spring_constant, _] for each edge.\n",
        "        - globals: Gx2 tf.Tensor containing the gravitational constant.\n",
        "    steps: Integer; the length of trajectory to generate.\n",
        "    step_size: Scalar.\n",
        "    node_noise_level: Maximum distance to perturb nodes' x and y coordinates.\n",
        "    edge_noise_level: Maximum amount to perturb edge spring constants.\n",
        "    global_noise_level: Maximum amount to perturb the Y component of gravity.\n",
        "\n",
        "  Returns:\n",
        "    A pair of:\n",
        "    - The input graph, but with rest lengths computed and noise applied.\n",
        "    - A `steps+1`xNx5 tf.Tensor of the node features at each step.\n",
        "  \"\"\"\n",
        "  graph = apply_noise(graph, node_noise_level, edge_noise_level,\n",
        "                      global_noise_level)\n",
        "  graph = set_rest_lengths(graph)\n",
        "  _, n = roll_out_physics(simulator, graph, steps, step_size)\n",
        "  return graph, n\n",
        "\n",
        "\n",
        "def create_loss_ops(target_op, output_ops):\n",
        "  \"\"\"Create supervised loss operations from targets and outputs.\n",
        "\n",
        "  Args:\n",
        "    target_op: The target velocity tf.Tensor.\n",
        "    output_ops: The list of outp\n",
        "ValueError: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`\n",
        "\n",
        "ut graphs from the model.\n",
        "\n",
        "  Returns:\n",
        "    A list of loss values (tf.Tensor), one per output op.\n",
        "  \"\"\"\n",
        "  loss_ops = [\n",
        "      tf.reduce_mean(\n",
        "          tf.reduce_sum((output_op.nodes - target_op[..., 2:4])**2, axis=-1))\n",
        "      for output_op in output_ops\n",
        "  ]\n",
        "  return loss_ops\n",
        "\n",
        "\n",
        "def make_all_runnable_in_session(*args):\n",
        "  \"\"\"Apply make_runnable_in_session to an iterable of graphs.\"\"\"\n",
        "  return [utils_tf.make_runnable_in_session(a) for a in args]\n",
        "\n",
        "def print_graphs_tuple(graphs_tuple):\n",
        "  from graph_nets import graphs\n",
        "  print(\"Shapes of `GraphsTuple`'s fields:\")\n",
        "  print(graphs_tuple.map(lambda x: x if x is None else x.shape, fields=graphs.ALL_FIELDS))\n",
        "  \n",
        "  print(\"\\nData contained in `GraphsTuple`'s fields:\")\n",
        "  print(\"globals:\\n{}\".format(graphs_tuple.globals))\n",
        "  print(\"nodes:\\n{}\".format(graphs_tuple.nodes))\n",
        "  print(\"edges:\\n{}\".format(graphs_tuple.edges))\n",
        "  print(\"senders:\\n{}\".format(graphs_tuple.senders))\n",
        "  print(\"receivers:\\n{}\".format(graphs_tuple.receivers))\n",
        "  print(\"n_node:\\n{}\".format(graphs_tuple.n_node))\n",
        "  print(\"n_edge:\\n{}\".format(graphs_tuple.n_edge))\n",
        "  \n",
        "# pylint: enable=redefined-outer-name\n",
        "\n",
        "def generate_perms(num_nodes):\n",
        "  with tf.Session():\n",
        "    num_nodes = num_nodes.eval()\n",
        "  \n",
        "  return [np.array(np.random.permutation(n)) for n in num_nodes]\n",
        "\n",
        "def permute_data(gs, perms):\n",
        "  with tf.Session():\n",
        "    gs = gs.map(lambda tensor: tensor.eval(), fields=graphs.ALL_FIELDS)\n",
        "  gs = utils_np.graphs_tuple_to_data_dicts(gs)\n",
        "  \n",
        "  if len(gs) != len(perms):\n",
        "    raise Exception(\"gs ({}) and perms ({}) should  have the same size\".format(len(gs), len(perms)))\n",
        "  # Generate random permutation\n",
        "  resp = []\n",
        "  for g, p in zip(gs, perms):\n",
        "    if len(p) != len(g[\"nodes\"]):\n",
        "      raise Exception(\"Permutation size ({}) should be the graph.nodes size ({})\".format(len(p), len(g[\"nodes\"])))\n",
        "    resp.append({\n",
        "        \"globals\": g[\"globals\"],\n",
        "        \"nodes\": g[\"nodes\"][p],\n",
        "        \"edges\": g[\"edges\"],\n",
        "        \"receivers\": list(p[np.array(g[\"receivers\"])]),\n",
        "        \"senders\": list(p[np.array(g[\"senders\"])])\n",
        "    })\n",
        "  gs = resp\n",
        "  gs = utils_tf.data_dicts_to_graphs_tuple(gs)\n",
        "  return gs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "pf7u0zuN_ktd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "98c42a0e-4932-4447-a8b2-f8a366d03f8e"
      },
      "source": [
        "#@title Set up model training and evaluation  { form-width: \"30%\" }\n",
        "\n",
        "# The model we explore includes three components:\n",
        "# - An \"Encoder\" graph net, which independently encodes the edge, node, and\n",
        "#   global attributes (does not compute relations etc.).\n",
        "# - A \"Core\" graph net, which performs N rounds of processing (message-passing)\n",
        "#   steps. The input to the Core is the concatenation of the Encoder's output\n",
        "#   and the previous output of the Core (labeled \"Hidden(t)\" below, where \"t\" is\n",
        "#   the processing step).\n",
        "# - A \"Decoder\" graph net, which independently decodes the edge, node, and\n",
        "#   global attributes (does not compute relations etc.), on each\n",
        "#   message-passing step.\n",
        "#\n",
        "#                     Hidden(t)   Hidden(t+1)\n",
        "#                        |            ^\n",
        "#           *---------*  |  *------*  |  *---------*\n",
        "#           |         |  |  |      |  |  |         |\n",
        "# Input --->| Encoder |  *->| Core |--*->| Decoder |---> Output(t)\n",
        "#           |         |---->|      |     |         |\n",
        "#           *---------*     *------*     *---------*\n",
        "#\n",
        "# The model is trained by supervised learning. Input mass-spring systems are\n",
        "# procedurally generated, where the nodes represent the positions, velocities,\n",
        "# and indicators of whether the mass is fixed in space or free to move, the\n",
        "# edges represent the spring constant and spring rest length, and the global\n",
        "# attribute represents the variable coefficient of gravitational acceleration.\n",
        "# The outputs/targets have the same structure, with the nodes representing the\n",
        "# masses' next-step states.\n",
        "#\n",
        "# The training loss is computed on the output of each processing step. The\n",
        "# reason for this is to encourage the model to try to solve the problem in as\n",
        "# few steps as possible. It also helps make the output of intermediate steps\n",
        "# more interpretable.\n",
        "#\n",
        "# There's no need for a separate evaluate dataset because the inputs are\n",
        "# never repeated, so the training loss is the measure of performance on graphs\n",
        "# from the input distribution.\n",
        "#\n",
        "# We also evaluate how well the models generalize to systems which are one mass\n",
        "# larger, and smaller, than those from the training distribution. The loss is\n",
        "# computed as the mean over a 50-step rollout, where each step's input is the\n",
        "# the previous step's output.\n",
        "#\n",
        "# Variables with the suffix _tr are training parameters, and variables with the\n",
        "# suffix _ge are test/generalization parameters.\n",
        "#\n",
        "# After around 10000-20000 training iterations the model reaches good\n",
        "# performance on mass-spring systems with 5-8 masses.\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "rand = np.random.RandomState(SEED)\n",
        "\n",
        "# Model parameters.\n",
        "num_processing_steps_tr = 1\n",
        "num_processing_steps_ge = 1\n",
        "\n",
        "# Data / training parameters.\n",
        "num_training_iterations = 100000\n",
        "batch_size_tr = 256\n",
        "batch_size_ge = 100\n",
        "num_time_steps = 50\n",
        "step_size = 0.1\n",
        "num_masses_min_max_tr = (5, 9)\n",
        "dist_between_masses_min_max_tr = (0.2, 1.0)\n",
        "\n",
        "# Create the model.\n",
        "model = models.EncodeProcessDecode(node_output_size=2)\n",
        "\n",
        "# Data.\n",
        "# Base graphs for training.\n",
        "num_masses_tr = rand.randint(*num_masses_min_max_tr, size=batch_size_tr)\n",
        "dist_between_masses_tr = rand.uniform(\n",
        "    *dist_between_masses_min_max_tr, size=batch_size_tr)\n",
        "static_graph_tr = [\n",
        "    base_graph(n, d) for n, d in zip(num_masses_tr, dist_between_masses_tr)\n",
        "]\n",
        "base_graph_tr = utils_tf.data_dicts_to_graphs_tuple(static_graph_tr)\n",
        "\n",
        "# Base graphs for testing.\n",
        "# 4 masses 1m apart in a chain like structure.\n",
        "base_graph_4_ge = utils_tf.data_dicts_to_graphs_tuple(\n",
        "    [base_graph(4, 0.5)] * batch_size_ge)\n",
        "# 9 masses 0.5m apart in a chain like structure.\n",
        "base_graph_9_ge = utils_tf.data_dicts_to_graphs_tuple(\n",
        "    [base_graph(9, 0.5)] * batch_size_ge)\n",
        "\n",
        "# True physics simulator for data generation.\n",
        "simulator = SpringMassSimulator(step_size=step_size)\n",
        "\n",
        "# Training.\n",
        "# Generate a training trajectory by adding noise to initial\n",
        "# position, spring constants and gravity\n",
        "initial_conditions_tr, true_trajectory_tr = generate_trajectory(\n",
        "    simulator,\n",
        "    base_graph_tr,\n",
        "    num_time_steps,\n",
        "    step_size,\n",
        "    node_noise_level=0.04,\n",
        "    edge_noise_level=5.0,\n",
        "    global_noise_level=1.0)\n",
        "\n",
        "# Random start step.\n",
        "t = tf.random_uniform([], minval=0, maxval=num_time_steps - 1, dtype=tf.int32)\n",
        "input_graph_tr = initial_conditions_tr.replace(nodes=true_trajectory_tr[t])\n",
        "target_nodes_tr = true_trajectory_tr[t + 1]\n",
        "output_ops_tr = model(input_graph_tr, num_processing_steps_tr)\n",
        "\n",
        "# Test data: 4-mass string.\n",
        "initial_conditions_4_ge, true_trajectory_4_ge = generate_trajectory(\n",
        "    lambda x: model(x, num_processing_steps_ge),\n",
        "    base_graph_4_ge,\n",
        "    num_time_steps,\n",
        "    step_size,\n",
        "    node_noise_level=0.04,\n",
        "    edge_noise_level=5.0,\n",
        "    global_noise_level=1.0)\n",
        "\n",
        "_, true_nodes_rollout_4_ge = roll_out_physics(\n",
        "    simulator, initial_conditions_4_ge, num_time_steps, step_size)\n",
        "\n",
        "_, predicted_nodes_rollout_4_ge = roll_out_physics(\n",
        "    lambda x: model(x, num_processing_steps_ge), initial_conditions_4_ge,\n",
        "    num_time_steps, step_size)\n",
        "\n",
        "# Test data: 9-mass string.\n",
        "initial_conditions_9_ge, true_trajectory_9_ge = generate_trajectory(\n",
        "    lambda x: model(x, num_processing_steps_ge),\n",
        "    base_graph_9_ge,\n",
        "    num_time_steps,\n",
        "    step_size,\n",
        "    node_noise_level=0.04,\n",
        "    edge_noise_level=5.0,\n",
        "    global_noise_level=1.0)\n",
        "\n",
        "_, true_nodes_rollout_9_ge = roll_out_physics(\n",
        "    simulator, initial_conditions_9_ge, num_time_steps, step_size)\n",
        "\n",
        "_, predicted_nodes_rollout_9_ge = roll_out_physics(\n",
        "    lambda x: model(x, num_processing_steps_ge), initial_conditions_9_ge,\n",
        "    num_time_steps, step_size)\n",
        "\n",
        "\n",
        "\n",
        "########### PERMUTATED TEST DATA ###########\n",
        "perms_4 = generate_perms(initial_conditions_4_ge.n_node)\n",
        "initial_conditions_4_ge_perm = permute_data(initial_conditions_4_ge, perms_4)\n",
        "\n",
        "perms_9 = generate_perms(initial_conditions_9_ge.n_node)\n",
        "initial_conditions_9_ge_perm = permute_data(initial_conditions_9_ge, perms_9)\n",
        "\n",
        "# # Initial conditions\n",
        "# g4 = initial_conditions_4_ge\n",
        "\n",
        "# from graph_nets import graphs\n",
        "# with tf.Session():\n",
        "#     g4 = g4.map(lambda tensor: tensor.eval(), fields=graphs.ALL_FIELDS)\n",
        "\n",
        "# print_graphs_tuple(g4)\n",
        "\n",
        "# g4 = utils_np.graphs_tuple_to_data_dicts(g4)\n",
        "\n",
        "# import json\n",
        "# print(\"Data dicts before Permuting\")\n",
        "# print(g4)\n",
        "\n",
        "# # Generate random permutation\n",
        "\n",
        "# resp = []\n",
        "# for g in g4:\n",
        "#   p = np.array(np.random.permutation(len(g[\"nodes\"])))\n",
        "#   resp.append({\n",
        "#       \"globals\": g[\"globals\"],\n",
        "#       \"nodes\": g[\"nodes\"][p],\n",
        "#       \"edges\": g[\"edges\"],\n",
        "#       \"receivers\": list(p[np.array(g[\"senders\"])]),\n",
        "#       \"senders\": list(p[np.array(g[\"receivers\"])])\n",
        "#     })\n",
        "# g4 = resp\n",
        "# print(\"Data dicts after permuting\")\n",
        "# print(g4)\n",
        "# g4 = utils_tf.data_dicts_to_graphs_tuple(g4)\n",
        "\n",
        "# print_graphs_tuple(g4)\n",
        "# initial_conditions_4_ge_perm = g4\n",
        "\n",
        "# #print(utils_np.graphs_tuple_to_data_dicts(initial_conditions_4_ge_perm))\n",
        "# initial_conditions_9_ge_perm = initial_conditions_9_ge\n",
        "\n",
        "\n",
        "_, true_nodes_rollout_4_ge_perm = roll_out_physics(\n",
        "    simulator, initial_conditions_4_ge_perm, num_time_steps, step_size)\n",
        "\n",
        "_, true_nodes_rollout_9_ge_perm = roll_out_physics(\n",
        "    simulator, initial_conditions_9_ge_perm, num_time_steps, step_size)\n",
        "\n",
        "# Predicted nodes\n",
        "_, predicted_nodes_rollout_4_ge_perm = roll_out_physics(\n",
        "    lambda x: model(x, num_processing_steps_ge), initial_conditions_4_ge_perm,\n",
        "    num_time_steps, step_size)\n",
        "_, predicted_nodes_rollout_9_ge_perm = roll_out_physics(\n",
        "    lambda x: model(x, num_processing_steps_ge), initial_conditions_9_ge_perm,\n",
        "    num_time_steps, step_size)\n",
        "############################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Training loss.\n",
        "loss_ops_tr = create_loss_ops(target_nodes_tr, output_ops_tr)\n",
        "# Training loss across processing steps.\n",
        "loss_op_tr = sum(loss_ops_tr) / num_processing_steps_tr\n",
        "\n",
        "# Test/generalization loss: 4-mass.\n",
        "loss_op_4_ge = tf.reduce_mean(\n",
        "    tf.reduce_sum(\n",
        "        (predicted_nodes_rollout_4_ge[..., 2:4] -\n",
        "         true_nodes_rollout_4_ge[..., 2:4])**2,\n",
        "        axis=-1))\n",
        "\n",
        "# Test/generalization loss: 9-mass string.\n",
        "loss_op_9_ge = tf.reduce_mean(\n",
        "    tf.reduce_sum(\n",
        "        (predicted_nodes_rollout_9_ge[..., 2:4] -\n",
        "         true_nodes_rollout_9_ge[..., 2:4])**2,\n",
        "        axis=-1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########### PERMUTATION LOSS ###########\n",
        "# Test/generalization loss: 4-mass.\n",
        "loss_op_4_ge_perm = tf.reduce_mean(\n",
        "    tf.reduce_sum(\n",
        "        (predicted_nodes_rollout_4_ge_perm[..., 2:4] -\n",
        "         true_nodes_rollout_4_ge_perm[..., 2:4])**2,\n",
        "        axis=-1))\n",
        "\n",
        "# Test/generalization loss: 9-mass string.\n",
        "loss_op_9_ge_perm = tf.reduce_mean(\n",
        "    tf.reduce_sum(\n",
        "        (predicted_nodes_rollout_9_ge_perm[..., 2:4] -\n",
        "         true_nodes_rollout_9_ge_perm[..., 2:4])**2,\n",
        "        axis=-1))\n",
        "########################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Optimizer.\n",
        "learning_rate = 1e-3\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "step_op = optimizer.minimize(loss_op_tr)\n",
        "\n",
        "input_graph_tr = make_all_runnable_in_session(input_graph_tr)\n",
        "initial_conditions_4_ge = make_all_runnable_in_session(initial_conditions_4_ge)\n",
        "initial_conditions_9_ge = make_all_runnable_in_session(initial_conditions_9_ge)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########### PERMUTATION INITIAL CONDITIONS (TEST ONLY) ###########\n",
        "initial_conditions_4_ge_perm = make_all_runnable_in_session(initial_conditions_4_ge_perm)\n",
        "initial_conditions_9_ge_perm = make_all_runnable_in_session(initial_conditions_9_ge_perm)\n",
        "##################################################################"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "TpABTYk0Ap-V",
        "colab": {}
      },
      "source": [
        "#@title Reset session  { form-width: \"30%\" }\n",
        "\n",
        "# This cell resets the Tensorflow session, but keeps the same computational\n",
        "# graph.\n",
        "\n",
        "try:\n",
        "  sess.close()\n",
        "except NameError:\n",
        "  pass\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "last_iteration = 0\n",
        "logged_iterations = []\n",
        "losses_tr = []\n",
        "losses_4_ge = []\n",
        "losses_9_ge = []\n",
        "losses_4_ge_perm = []\n",
        "losses_9_ge_perm = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "4PCPvXiHA7q7",
        "outputId": "619ab0c3-63ba-455b-a51c-34ccac82fc95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3063
        }
      },
      "source": [
        "#@title Run training  { form-width: \"30%\" }\n",
        "\n",
        "# You can interrupt this cell's training loop at any time, and visualize the\n",
        "# intermediate results by running the next cell (below). You can then resume\n",
        "# training by simply executing this cell again.\n",
        "\n",
        "# How much time between logging and printing the current results.\n",
        "log_every_seconds = 20\n",
        "\n",
        "print(\"# (iteration number), T (elapsed seconds), \"\n",
        "      \"Ltr (training 1-step loss), \"\n",
        "      \"Lge4 (test/generalization rollout loss for 4-mass strings), \"\n",
        "      \"Lge9 (test/generalization rollout loss for 9-mass strings), \"\n",
        "      \"Lge4_perm (test/generalization rollout loss for 4-mass strings), \"\n",
        "      \"Lge9_perm (test/generalization rollout loss for 9-mass strings)\")\n",
        "\n",
        "start_time = time.time()\n",
        "last_log_time = start_time\n",
        "for iteration in range(last_iteration, num_training_iterations):\n",
        "  last_iteration = iteration\n",
        "  train_values = sess.run({\n",
        "      \"step\": step_op,\n",
        "      \"loss\": loss_op_tr,\n",
        "      \"input_graph\": input_graph_tr,\n",
        "      \"target_nodes\": target_nodes_tr,\n",
        "      \"outputs\": output_ops_tr\n",
        "  })\n",
        "  the_time = time.time()\n",
        "  elapsed_since_last_log = the_time - last_log_time\n",
        "  if elapsed_since_last_log > log_every_seconds:\n",
        "    last_log_time = the_time\n",
        "    test_values = sess.run({\n",
        "        \"loss_4\": loss_op_4_ge,\n",
        "        \"true_rollout_4\": true_nodes_rollout_4_ge,\n",
        "        \"predicted_rollout_4\": predicted_nodes_rollout_4_ge,\n",
        "        \"loss_9\": loss_op_9_ge,\n",
        "        \"true_rollout_9\": true_nodes_rollout_9_ge,\n",
        "        \"predicted_rollout_9\": predicted_nodes_rollout_9_ge,\n",
        "        \n",
        "        \n",
        "        \n",
        "        ################ PERMUTATION TEST VALUES ################\n",
        "        \"loss_4_perm\": loss_op_4_ge_perm,\n",
        "        \"true_rollout_4_perm\": true_nodes_rollout_4_ge_perm,\n",
        "        \"predicted_rollout_4_perm\": predicted_nodes_rollout_4_ge_perm,\n",
        "        \"loss_9_perm\": loss_op_9_ge_perm,\n",
        "        \"true_rollout_9_perm\": true_nodes_rollout_9_ge_perm,\n",
        "        \"predicted_rollout_9_perm\": predicted_nodes_rollout_9_ge_perm\n",
        "        #########################################################\n",
        "        \n",
        "        \n",
        "    })\n",
        "    elapsed = time.time() - start_time\n",
        "    losses_tr.append(train_values[\"loss\"])\n",
        "    losses_4_ge.append(test_values[\"loss_4\"])\n",
        "    losses_9_ge.append(test_values[\"loss_9\"])\n",
        "    ################ PERMUTATION TEST VALUES ################\n",
        "    losses_4_ge_perm.append(test_values[\"loss_4_perm\"])\n",
        "    losses_9_ge_perm.append(test_values[\"loss_9_perm\"])\n",
        "    #########################################################\n",
        "    logged_iterations.append(iteration)\n",
        "    print(\"# {:05d}, T {:.1f}, Ltr {:.4f}, Lge4 {:.4f}, Lge9 {:.4f}, Lge4_perm {:.4f}, Lge9_perm {:.4f}\"\n",
        "          .format(iteration, elapsed, train_values[\"loss\"], test_values[\"loss_4\"],test_values[\"loss_9\"],\n",
        "                  test_values[\"loss_4_perm\"],test_values[\"loss_9_perm\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# (iteration number), T (elapsed seconds), Ltr (training 1-step loss), Lge4 (test/generalization rollout loss for 4-mass strings), Lge9 (test/generalization rollout loss for 9-mass strings), Lge4_perm (test/generalization rollout loss for 4-mass strings), Lge9_perm (test/generalization rollout loss for 9-mass strings)\n",
            "# 00083, T 23.9, Ltr 2.3992, Lge4 5.0334, Lge9 15.6307, Lge4_perm 159.3590, Lge9_perm 278.3015\n",
            "# 00161, T 41.4, Ltr 1.8735, Lge4 5.4765, Lge9 6.5361, Lge4_perm 160.3098, Lge9_perm 280.2669\n",
            "# 00252, T 61.6, Ltr 1.0020, Lge4 4.8484, Lge9 9.0458, Lge4_perm 156.6169, Lge9_perm 280.5276\n",
            "# 00343, T 81.5, Ltr 1.6102, Lge4 4.4438, Lge9 14.2916, Lge4_perm 157.8775, Lge9_perm 275.8437\n",
            "# 00435, T 101.8, Ltr 1.7792, Lge4 3.2919, Lge9 15.4210, Lge4_perm 156.5561, Lge9_perm 277.2584\n",
            "# 00526, T 121.8, Ltr 1.6158, Lge4 6.2982, Lge9 7.7808, Lge4_perm 158.9884, Lge9_perm 283.8797\n",
            "# 00617, T 141.9, Ltr 1.2940, Lge4 2.6441, Lge9 11.2789, Lge4_perm 156.5426, Lge9_perm 279.7445\n",
            "# 00709, T 162.2, Ltr 1.4450, Lge4 5.7857, Lge9 11.5076, Lge4_perm 158.4276, Lge9_perm 281.1052\n",
            "# 00800, T 182.4, Ltr 0.8529, Lge4 2.0480, Lge9 15.3796, Lge4_perm 155.1940, Lge9_perm 275.3318\n",
            "# 00891, T 202.4, Ltr 1.2411, Lge4 2.1731, Lge9 18.8182, Lge4_perm 155.0993, Lge9_perm 276.0207\n",
            "# 00982, T 222.6, Ltr 1.2012, Lge4 3.2519, Lge9 13.5221, Lge4_perm 159.8950, Lge9_perm 280.2721\n",
            "# 01072, T 242.7, Ltr 1.2825, Lge4 2.3329, Lge9 16.0236, Lge4_perm 155.6318, Lge9_perm 275.0272\n",
            "# 01162, T 262.7, Ltr 1.1802, Lge4 1.9031, Lge9 17.4559, Lge4_perm 156.3714, Lge9_perm 277.7873\n",
            "# 01253, T 282.9, Ltr 1.2987, Lge4 1.8914, Lge9 9.9026, Lge4_perm 158.6321, Lge9_perm 278.6790\n",
            "# 01344, T 303.1, Ltr 0.7162, Lge4 2.1328, Lge9 7.8958, Lge4_perm 158.4636, Lge9_perm 280.4673\n",
            "# 01433, T 323.2, Ltr 0.7382, Lge4 1.9471, Lge9 14.3269, Lge4_perm 159.0154, Lge9_perm 276.5221\n",
            "# 01524, T 343.3, Ltr 0.9939, Lge4 1.7631, Lge9 15.5220, Lge4_perm 156.3032, Lge9_perm 275.3312\n",
            "# 01615, T 363.4, Ltr 0.6098, Lge4 2.0672, Lge9 11.2299, Lge4_perm 156.7005, Lge9_perm 274.6253\n",
            "# 01706, T 383.5, Ltr 1.0641, Lge4 2.5103, Lge9 9.7598, Lge4_perm 155.1852, Lge9_perm 274.0559\n",
            "# 01797, T 403.7, Ltr 0.0860, Lge4 2.3165, Lge9 7.9423, Lge4_perm 155.8723, Lge9_perm 277.0001\n",
            "# 01888, T 423.8, Ltr 0.1276, Lge4 2.2983, Lge9 8.4933, Lge4_perm 155.4340, Lge9_perm 274.9260\n",
            "# 01979, T 443.9, Ltr 0.2164, Lge4 1.6822, Lge9 7.8188, Lge4_perm 156.0655, Lge9_perm 278.1831\n",
            "# 02070, T 464.0, Ltr 0.8434, Lge4 2.1123, Lge9 6.9889, Lge4_perm 156.4368, Lge9_perm 278.6109\n",
            "# 02160, T 484.0, Ltr 0.4666, Lge4 1.7743, Lge9 5.5523, Lge4_perm 156.3654, Lge9_perm 279.5766\n",
            "# 02250, T 504.2, Ltr 0.9179, Lge4 2.2493, Lge9 10.0471, Lge4_perm 156.4037, Lge9_perm 278.0027\n",
            "# 02341, T 524.4, Ltr 0.2873, Lge4 1.9103, Lge9 12.6582, Lge4_perm 156.0331, Lge9_perm 277.6328\n",
            "# 02430, T 544.3, Ltr 0.8721, Lge4 3.7676, Lge9 4.1410, Lge4_perm 158.3676, Lge9_perm 283.5513\n",
            "# 02521, T 564.5, Ltr 0.9685, Lge4 1.9114, Lge9 5.5667, Lge4_perm 157.4615, Lge9_perm 283.9985\n",
            "# 02612, T 584.6, Ltr 0.6754, Lge4 1.2413, Lge9 7.2035, Lge4_perm 156.2621, Lge9_perm 279.7318\n",
            "# 02702, T 604.7, Ltr 0.3609, Lge4 1.8774, Lge9 8.8853, Lge4_perm 155.5996, Lge9_perm 273.4878\n",
            "# 02790, T 624.8, Ltr 0.3600, Lge4 2.6126, Lge9 8.5663, Lge4_perm 156.1396, Lge9_perm 274.7595\n",
            "# 02881, T 645.0, Ltr 0.7951, Lge4 1.3673, Lge9 6.2091, Lge4_perm 156.4426, Lge9_perm 280.8336\n",
            "# 02971, T 665.0, Ltr 0.8101, Lge4 10.5250, Lge9 12.4317, Lge4_perm 161.4946, Lge9_perm 280.7623\n",
            "# 03061, T 684.9, Ltr 0.9630, Lge4 2.1159, Lge9 9.7246, Lge4_perm 157.0779, Lge9_perm 277.5318\n",
            "# 03153, T 705.1, Ltr 0.5858, Lge4 2.0038, Lge9 5.5477, Lge4_perm 157.2764, Lge9_perm 280.6941\n",
            "# 03244, T 725.1, Ltr 0.5000, Lge4 1.5381, Lge9 4.7331, Lge4_perm 156.7002, Lge9_perm 279.1369\n",
            "# 03336, T 745.3, Ltr 0.6742, Lge4 2.2319, Lge9 10.9756, Lge4_perm 155.5358, Lge9_perm 273.4607\n",
            "# 03426, T 765.3, Ltr 0.4459, Lge4 1.2306, Lge9 4.2421, Lge4_perm 156.0464, Lge9_perm 279.2257\n",
            "# 03516, T 785.5, Ltr 0.0722, Lge4 2.0258, Lge9 5.6036, Lge4_perm 157.1845, Lge9_perm 282.1340\n",
            "# 03607, T 805.6, Ltr 0.7058, Lge4 2.9505, Lge9 8.2303, Lge4_perm 156.5404, Lge9_perm 274.7188\n",
            "# 03698, T 825.7, Ltr 0.5302, Lge4 0.8654, Lge9 8.1329, Lge4_perm 156.5884, Lge9_perm 280.4599\n",
            "# 03789, T 845.9, Ltr 0.5291, Lge4 1.4664, Lge9 4.8432, Lge4_perm 156.2192, Lge9_perm 279.6839\n",
            "# 03878, T 865.9, Ltr 0.6129, Lge4 1.2338, Lge9 8.5395, Lge4_perm 156.6419, Lge9_perm 278.4761\n",
            "# 03969, T 885.9, Ltr 0.6978, Lge4 1.3375, Lge9 5.0938, Lge4_perm 156.3006, Lge9_perm 275.6947\n",
            "# 04060, T 906.1, Ltr 0.6941, Lge4 2.1901, Lge9 7.8404, Lge4_perm 155.3704, Lge9_perm 272.9751\n",
            "# 04151, T 926.2, Ltr 0.3630, Lge4 1.0998, Lge9 8.7093, Lge4_perm 156.1956, Lge9_perm 278.5208\n",
            "# 04241, T 946.2, Ltr 0.5363, Lge4 1.8398, Lge9 6.5731, Lge4_perm 155.1682, Lge9_perm 274.4175\n",
            "# 04331, T 966.2, Ltr 0.2813, Lge4 1.4816, Lge9 3.1592, Lge4_perm 156.6084, Lge9_perm 278.2006\n",
            "# 04422, T 986.5, Ltr 0.4837, Lge4 2.7315, Lge9 4.9710, Lge4_perm 157.6385, Lge9_perm 283.5465\n",
            "# 04513, T 1006.5, Ltr 0.4530, Lge4 0.9604, Lge9 6.8397, Lge4_perm 156.9670, Lge9_perm 280.3543\n",
            "# 04604, T 1026.5, Ltr 0.4070, Lge4 1.0465, Lge9 4.0253, Lge4_perm 156.1450, Lge9_perm 279.8537\n",
            "# 04695, T 1046.6, Ltr 0.3123, Lge4 1.3994, Lge9 4.6231, Lge4_perm 156.4244, Lge9_perm 277.0943\n",
            "# 04786, T 1066.6, Ltr 0.7356, Lge4 1.2886, Lge9 11.2183, Lge4_perm 157.4305, Lge9_perm 279.4596\n",
            "# 04877, T 1086.8, Ltr 0.6824, Lge4 2.6839, Lge9 10.2959, Lge4_perm 157.8188, Lge9_perm 277.2005\n",
            "# 04967, T 1106.9, Ltr 0.2866, Lge4 2.3863, Lge9 11.4197, Lge4_perm 157.0093, Lge9_perm 276.9585\n",
            "# 05058, T 1127.0, Ltr 0.5693, Lge4 2.0564, Lge9 9.1292, Lge4_perm 156.2429, Lge9_perm 276.7057\n",
            "# 05150, T 1147.1, Ltr 0.4826, Lge4 1.7066, Lge9 6.7280, Lge4_perm 157.0792, Lge9_perm 279.8650\n",
            "# 05242, T 1167.2, Ltr 0.4801, Lge4 1.5967, Lge9 10.0259, Lge4_perm 156.9017, Lge9_perm 276.2955\n",
            "# 05333, T 1187.3, Ltr 0.4782, Lge4 1.5025, Lge9 8.4585, Lge4_perm 157.2597, Lge9_perm 279.2785\n",
            "# 05424, T 1207.4, Ltr 0.5763, Lge4 3.2977, Lge9 8.7742, Lge4_perm 156.9373, Lge9_perm 274.9055\n",
            "# 05516, T 1227.6, Ltr 0.0739, Lge4 1.0875, Lge9 7.7205, Lge4_perm 156.8803, Lge9_perm 277.2697\n",
            "# 05605, T 1247.8, Ltr 0.2466, Lge4 1.7052, Lge9 4.1235, Lge4_perm 157.8384, Lge9_perm 278.5600\n",
            "# 05697, T 1267.9, Ltr 0.4491, Lge4 1.7000, Lge9 4.9940, Lge4_perm 157.6384, Lge9_perm 279.1741\n",
            "# 05787, T 1287.9, Ltr 0.4280, Lge4 1.9874, Lge9 3.9692, Lge4_perm 157.3110, Lge9_perm 277.9186\n",
            "# 05879, T 1307.9, Ltr 0.4196, Lge4 2.1663, Lge9 3.8764, Lge4_perm 157.3699, Lge9_perm 277.4321\n",
            "# 05970, T 1328.1, Ltr 0.4783, Lge4 1.6735, Lge9 3.5353, Lge4_perm 157.4322, Lge9_perm 277.8312\n",
            "# 06060, T 1348.1, Ltr 0.5203, Lge4 1.5377, Lge9 6.5136, Lge4_perm 156.4180, Lge9_perm 273.9736\n",
            "# 06152, T 1368.2, Ltr 0.4122, Lge4 1.8013, Lge9 6.6665, Lge4_perm 157.1725, Lge9_perm 280.8148\n",
            "# 06243, T 1388.4, Ltr 0.3175, Lge4 1.4545, Lge9 6.8092, Lge4_perm 157.4086, Lge9_perm 278.5062\n",
            "# 06335, T 1408.5, Ltr 0.3659, Lge4 1.5925, Lge9 3.7372, Lge4_perm 157.0048, Lge9_perm 279.1039\n",
            "# 06426, T 1428.6, Ltr 0.4366, Lge4 1.3404, Lge9 4.0458, Lge4_perm 158.0913, Lge9_perm 277.2657\n",
            "# 06517, T 1448.8, Ltr 0.4498, Lge4 1.5726, Lge9 5.5806, Lge4_perm 159.4176, Lge9_perm 283.7806\n",
            "# 06608, T 1468.8, Ltr 0.5228, Lge4 1.7115, Lge9 6.3541, Lge4_perm 156.6773, Lge9_perm 275.9510\n",
            "# 06700, T 1488.9, Ltr 0.0492, Lge4 2.5224, Lge9 7.6520, Lge4_perm 158.0052, Lge9_perm 277.2339\n",
            "# 06792, T 1509.1, Ltr 0.3352, Lge4 2.2542, Lge9 5.5332, Lge4_perm 157.8371, Lge9_perm 277.9950\n",
            "# 06884, T 1529.3, Ltr 0.3769, Lge4 1.6290, Lge9 3.6599, Lge4_perm 157.6705, Lge9_perm 277.0212\n",
            "# 06975, T 1549.4, Ltr 0.4582, Lge4 1.5151, Lge9 4.2686, Lge4_perm 156.9388, Lge9_perm 278.2219\n",
            "# 07067, T 1569.5, Ltr 0.1699, Lge4 1.3992, Lge9 3.9136, Lge4_perm 157.6747, Lge9_perm 277.5392\n",
            "# 07158, T 1589.7, Ltr 0.4243, Lge4 1.1161, Lge9 4.0049, Lge4_perm 157.4470, Lge9_perm 279.1619\n",
            "# 07249, T 1609.8, Ltr 0.0806, Lge4 1.6759, Lge9 6.5210, Lge4_perm 156.9751, Lge9_perm 276.8141\n",
            "# 07340, T 1629.8, Ltr 0.3626, Lge4 1.2504, Lge9 4.1295, Lge4_perm 157.5964, Lge9_perm 279.3787\n",
            "# 07431, T 1649.9, Ltr 0.0581, Lge4 1.3190, Lge9 7.0640, Lge4_perm 158.2982, Lge9_perm 280.1183\n",
            "# 07522, T 1670.0, Ltr 0.4594, Lge4 1.5960, Lge9 5.0580, Lge4_perm 157.0258, Lge9_perm 277.0415\n",
            "# 07614, T 1690.2, Ltr 0.2439, Lge4 2.0745, Lge9 4.0278, Lge4_perm 157.3057, Lge9_perm 278.7744\n",
            "# 07706, T 1710.3, Ltr 0.2350, Lge4 1.5986, Lge9 7.7875, Lge4_perm 157.6615, Lge9_perm 277.4658\n",
            "# 07798, T 1730.5, Ltr 0.6561, Lge4 5.3181, Lge9 16.1646, Lge4_perm 160.2661, Lge9_perm 282.8232\n",
            "# 07889, T 1750.6, Ltr 0.6458, Lge4 1.4871, Lge9 7.2232, Lge4_perm 156.6924, Lge9_perm 274.8170\n",
            "# 07980, T 1770.7, Ltr 0.3509, Lge4 1.6889, Lge9 5.2884, Lge4_perm 156.8265, Lge9_perm 277.4364\n",
            "# 08072, T 1790.9, Ltr 0.0497, Lge4 1.4253, Lge9 7.2567, Lge4_perm 156.6630, Lge9_perm 275.7740\n",
            "# 08163, T 1810.9, Ltr 0.3386, Lge4 2.3798, Lge9 3.7571, Lge4_perm 158.3743, Lge9_perm 280.7772\n",
            "# 08254, T 1831.1, Ltr 0.3445, Lge4 2.0038, Lge9 4.5493, Lge4_perm 158.3196, Lge9_perm 283.8311\n",
            "# 08345, T 1851.2, Ltr 0.2801, Lge4 1.6437, Lge9 10.3304, Lge4_perm 157.4803, Lge9_perm 279.5440\n",
            "# 08433, T 1871.2, Ltr 0.4269, Lge4 3.8979, Lge9 9.2273, Lge4_perm 160.4664, Lge9_perm 282.3577\n",
            "# 08523, T 1891.3, Ltr 0.3126, Lge4 1.8455, Lge9 3.6179, Lge4_perm 157.8016, Lge9_perm 283.6498\n",
            "# 08614, T 1911.3, Ltr 0.3792, Lge4 1.9786, Lge9 6.7189, Lge4_perm 158.4937, Lge9_perm 283.2506\n",
            "# 08706, T 1931.6, Ltr 0.3327, Lge4 1.1346, Lge9 5.3257, Lge4_perm 157.7348, Lge9_perm 287.0202\n",
            "# 08797, T 1951.6, Ltr 0.3035, Lge4 1.1111, Lge9 5.3200, Lge4_perm 157.0058, Lge9_perm 276.8375\n",
            "# 08888, T 1971.7, Ltr 0.3725, Lge4 1.7341, Lge9 8.8608, Lge4_perm 158.1186, Lge9_perm 288.1908\n",
            "# 08979, T 1991.9, Ltr 0.3850, Lge4 1.9226, Lge9 4.9801, Lge4_perm 158.3224, Lge9_perm 282.6031\n",
            "# 09070, T 2012.0, Ltr 0.1383, Lge4 2.1461, Lge9 4.1895, Lge4_perm 158.4435, Lge9_perm 294.8770\n",
            "# 09162, T 2032.2, Ltr 0.1858, Lge4 1.7106, Lge9 7.7489, Lge4_perm 158.2455, Lge9_perm 282.5121\n",
            "# 09254, T 2052.3, Ltr 0.1607, Lge4 1.6137, Lge9 5.8472, Lge4_perm 158.6784, Lge9_perm 292.1476\n",
            "# 09345, T 2072.5, Ltr 0.0793, Lge4 1.5249, Lge9 3.9558, Lge4_perm 158.2353, Lge9_perm 280.8956\n",
            "# 09436, T 2092.6, Ltr 0.3454, Lge4 1.9948, Lge9 4.8571, Lge4_perm 159.8616, Lge9_perm 301.9317\n",
            "# 09527, T 2112.6, Ltr 0.1681, Lge4 1.5075, Lge9 12.1672, Lge4_perm 158.4960, Lge9_perm 293.7435\n",
            "# 09618, T 2132.6, Ltr 0.4186, Lge4 1.6536, Lge9 4.4183, Lge4_perm 158.9589, Lge9_perm 299.3825\n",
            "# 09709, T 2152.7, Ltr 0.2300, Lge4 1.4325, Lge9 7.8281, Lge4_perm 157.3130, Lge9_perm 280.3932\n",
            "# 09799, T 2172.8, Ltr 0.2928, Lge4 1.7683, Lge9 6.4176, Lge4_perm 159.2614, Lge9_perm 301.4263\n",
            "# 09889, T 2192.9, Ltr 0.0600, Lge4 1.9880, Lge9 6.5342, Lge4_perm 158.9570, Lge9_perm 291.6758\n",
            "# 09980, T 2212.9, Ltr 0.0610, Lge4 1.8079, Lge9 8.2203, Lge4_perm 159.2100, Lge9_perm 303.6495\n",
            "# 10071, T 2233.1, Ltr 0.1235, Lge4 1.8613, Lge9 13.5508, Lge4_perm 159.0524, Lge9_perm 298.1479\n",
            "# 10162, T 2253.2, Ltr 0.1757, Lge4 2.2752, Lge9 8.4893, Lge4_perm 158.6591, Lge9_perm 288.1682\n",
            "# 10253, T 2273.3, Ltr 0.0353, Lge4 1.5551, Lge9 3.5932, Lge4_perm 159.3401, Lge9_perm 289.2255\n",
            "# 10343, T 2293.4, Ltr 0.0327, Lge4 1.9754, Lge9 9.5808, Lge4_perm 159.6519, Lge9_perm 298.1671\n",
            "# 10434, T 2313.4, Ltr 0.2581, Lge4 1.7002, Lge9 15.8615, Lge4_perm 162.7004, Lge9_perm 298.3771\n",
            "# 10524, T 2333.6, Ltr 0.3397, Lge4 1.4995, Lge9 4.4400, Lge4_perm 159.5872, Lge9_perm 300.4199\n",
            "# 10615, T 2353.8, Ltr 0.1764, Lge4 2.9757, Lge9 3.7581, Lge4_perm 160.3493, Lge9_perm 298.2765\n",
            "# 10705, T 2373.9, Ltr 0.3611, Lge4 1.0070, Lge9 7.1837, Lge4_perm 159.3795, Lge9_perm 301.1349\n",
            "# 10796, T 2394.0, Ltr 0.3631, Lge4 2.1011, Lge9 11.7097, Lge4_perm 160.1854, Lge9_perm 293.7129\n",
            "# 10887, T 2414.0, Ltr 0.0603, Lge4 1.9146, Lge9 3.3287, Lge4_perm 158.8255, Lge9_perm 290.9828\n",
            "# 10977, T 2434.1, Ltr 0.2958, Lge4 2.6187, Lge9 3.2040, Lge4_perm 159.7762, Lge9_perm 294.4409\n",
            "# 11068, T 2454.0, Ltr 0.2362, Lge4 1.4160, Lge9 4.1232, Lge4_perm 159.3811, Lge9_perm 292.0233\n",
            "# 11159, T 2474.1, Ltr 0.3278, Lge4 1.5951, Lge9 4.0260, Lge4_perm 159.5509, Lge9_perm 294.3665\n",
            "# 11248, T 2494.2, Ltr 0.2425, Lge4 2.4299, Lge9 6.7519, Lge4_perm 160.1939, Lge9_perm 298.4947\n",
            "# 11338, T 2514.2, Ltr 0.2587, Lge4 1.9710, Lge9 3.2228, Lge4_perm 159.1453, Lge9_perm 296.9952\n",
            "# 11430, T 2534.3, Ltr 0.1939, Lge4 2.4380, Lge9 13.3797, Lge4_perm 159.3447, Lge9_perm 298.1305\n",
            "# 11521, T 2554.2, Ltr 0.2810, Lge4 1.8845, Lge9 3.8037, Lge4_perm 159.6736, Lge9_perm 289.9346\n",
            "# 11613, T 2574.4, Ltr 0.3491, Lge4 1.9478, Lge9 3.2060, Lge4_perm 159.7338, Lge9_perm 288.4207\n",
            "# 11703, T 2594.6, Ltr 0.2130, Lge4 2.7768, Lge9 12.9373, Lge4_perm 160.4149, Lge9_perm 287.7328\n",
            "# 11792, T 2614.4, Ltr 0.0556, Lge4 1.7757, Lge9 6.2469, Lge4_perm 159.6558, Lge9_perm 294.7043\n",
            "# 11884, T 2634.7, Ltr 0.2219, Lge4 3.6655, Lge9 4.9769, Lge4_perm 160.8889, Lge9_perm 299.3329\n",
            "# 11975, T 2654.7, Ltr 0.3069, Lge4 1.5294, Lge9 8.6137, Lge4_perm 160.1979, Lge9_perm 302.7224\n",
            "# 12066, T 2674.9, Ltr 0.2303, Lge4 1.6226, Lge9 3.5733, Lge4_perm 160.1095, Lge9_perm 297.3614\n",
            "# 12156, T 2695.0, Ltr 0.2474, Lge4 2.1800, Lge9 3.6140, Lge4_perm 160.0186, Lge9_perm 298.0987\n",
            "# 12246, T 2715.0, Ltr 0.0893, Lge4 2.0813, Lge9 3.9960, Lge4_perm 160.1570, Lge9_perm 298.2051\n",
            "# 12336, T 2735.0, Ltr 0.3477, Lge4 2.2257, Lge9 8.6340, Lge4_perm 159.6341, Lge9_perm 296.4009\n",
            "# 12427, T 2755.2, Ltr 0.1858, Lge4 2.2548, Lge9 4.6688, Lge4_perm 159.3730, Lge9_perm 287.5240\n",
            "# 12518, T 2775.3, Ltr 0.0273, Lge4 2.1563, Lge9 7.9235, Lge4_perm 159.6912, Lge9_perm 285.6789\n",
            "# 12609, T 2795.5, Ltr 0.2414, Lge4 2.0366, Lge9 4.9490, Lge4_perm 160.0521, Lge9_perm 286.2817\n",
            "# 12698, T 2815.5, Ltr 0.0253, Lge4 1.4831, Lge9 3.6309, Lge4_perm 159.6237, Lge9_perm 290.4462\n",
            "# 12788, T 2835.5, Ltr 0.2439, Lge4 2.1545, Lge9 4.8214, Lge4_perm 160.0883, Lge9_perm 285.8359\n",
            "# 12879, T 2855.6, Ltr 0.1307, Lge4 2.3458, Lge9 7.4594, Lge4_perm 160.4337, Lge9_perm 289.3003\n",
            "# 12970, T 2875.6, Ltr 0.2721, Lge4 1.7384, Lge9 4.2105, Lge4_perm 159.9719, Lge9_perm 292.1687\n",
            "# 13062, T 2895.9, Ltr 0.2427, Lge4 2.0326, Lge9 7.1958, Lge4_perm 159.6296, Lge9_perm 285.5126\n",
            "# 13151, T 2915.7, Ltr 0.3186, Lge4 2.1563, Lge9 4.3071, Lge4_perm 160.5848, Lge9_perm 290.4756\n",
            "# 13242, T 2935.9, Ltr 0.2404, Lge4 2.1556, Lge9 5.0041, Lge4_perm 160.1027, Lge9_perm 288.5640\n",
            "# 13334, T 2956.0, Ltr 0.2042, Lge4 1.9761, Lge9 9.7493, Lge4_perm 159.1964, Lge9_perm 285.9244\n",
            "# 13426, T 2976.1, Ltr 0.3241, Lge4 3.6742, Lge9 7.5633, Lge4_perm 162.4271, Lge9_perm 291.9486\n",
            "# 13518, T 2996.2, Ltr 0.2034, Lge4 1.8632, Lge9 8.4521, Lge4_perm 159.7856, Lge9_perm 286.5090\n",
            "# 13609, T 3016.3, Ltr 0.3111, Lge4 2.0833, Lge9 5.1577, Lge4_perm 159.7050, Lge9_perm 285.7018\n",
            "# 13700, T 3036.5, Ltr 0.1613, Lge4 1.5713, Lge9 5.7537, Lge4_perm 158.3533, Lge9_perm 284.3652\n",
            "# 13791, T 3056.5, Ltr 0.1942, Lge4 2.5647, Lge9 7.4191, Lge4_perm 159.3799, Lge9_perm 282.7653\n",
            "# 13883, T 3076.7, Ltr 0.1305, Lge4 2.5682, Lge9 5.4768, Lge4_perm 159.5565, Lge9_perm 285.2833\n",
            "# 13974, T 3096.8, Ltr 0.0408, Lge4 3.2842, Lge9 7.9678, Lge4_perm 160.4684, Lge9_perm 284.5267\n",
            "# 14062, T 3116.8, Ltr 0.2335, Lge4 2.5676, Lge9 4.3682, Lge4_perm 160.0578, Lge9_perm 284.9554\n",
            "# 14153, T 3136.9, Ltr 0.1250, Lge4 2.1055, Lge9 3.3858, Lge4_perm 159.7096, Lge9_perm 284.1451\n",
            "# 14243, T 3156.8, Ltr 0.1536, Lge4 2.7431, Lge9 3.1871, Lge4_perm 159.9604, Lge9_perm 285.5171\n",
            "# 14334, T 3177.1, Ltr 0.2458, Lge4 2.2996, Lge9 7.2313, Lge4_perm 159.2017, Lge9_perm 282.1551\n",
            "# 14425, T 3197.2, Ltr 0.1918, Lge4 2.6010, Lge9 3.2850, Lge4_perm 159.9088, Lge9_perm 284.2743\n",
            "# 14516, T 3217.5, Ltr 0.0349, Lge4 1.5001, Lge9 7.5572, Lge4_perm 160.0283, Lge9_perm 285.2772\n",
            "# 14606, T 3237.4, Ltr 0.1882, Lge4 2.3899, Lge9 10.0253, Lge4_perm 160.0513, Lge9_perm 283.0674\n",
            "# 14697, T 3257.5, Ltr 0.3028, Lge4 1.5478, Lge9 14.2800, Lge4_perm 159.9097, Lge9_perm 286.5226\n",
            "# 14788, T 3277.7, Ltr 0.2094, Lge4 2.1532, Lge9 4.2196, Lge4_perm 159.3353, Lge9_perm 286.8200\n",
            "# 14878, T 3297.7, Ltr 0.2266, Lge4 3.7903, Lge9 6.2472, Lge4_perm 160.3913, Lge9_perm 282.1099\n",
            "# 14968, T 3317.8, Ltr 0.1994, Lge4 1.2593, Lge9 3.1960, Lge4_perm 159.8177, Lge9_perm 285.9217\n",
            "# 15059, T 3337.8, Ltr 0.1614, Lge4 1.9859, Lge9 4.0006, Lge4_perm 159.7209, Lge9_perm 285.4926\n",
            "# 15150, T 3357.9, Ltr 0.0582, Lge4 2.0978, Lge9 5.6562, Lge4_perm 160.2116, Lge9_perm 287.4610\n",
            "# 15240, T 3378.1, Ltr 0.3081, Lge4 3.0964, Lge9 3.8549, Lge4_perm 160.3349, Lge9_perm 284.7364\n",
            "# 15331, T 3398.2, Ltr 0.3010, Lge4 2.1977, Lge9 3.9345, Lge4_perm 160.3753, Lge9_perm 285.8659\n",
            "# 15421, T 3418.5, Ltr 0.1846, Lge4 2.6847, Lge9 4.1313, Lge4_perm 160.1441, Lge9_perm 287.1296\n",
            "# 15511, T 3438.6, Ltr 0.2233, Lge4 2.3559, Lge9 4.7765, Lge4_perm 159.8735, Lge9_perm 281.7717\n",
            "# 15602, T 3458.6, Ltr 0.0536, Lge4 1.8639, Lge9 2.8485, Lge4_perm 160.0436, Lge9_perm 284.4365\n",
            "# 15694, T 3478.8, Ltr 0.1451, Lge4 2.1471, Lge9 4.3338, Lge4_perm 160.3953, Lge9_perm 286.4482\n",
            "# 15785, T 3498.9, Ltr 0.2826, Lge4 2.1345, Lge9 5.3436, Lge4_perm 160.4703, Lge9_perm 287.0199\n",
            "# 15877, T 3519.0, Ltr 0.2475, Lge4 2.9357, Lge9 2.7739, Lge4_perm 160.4248, Lge9_perm 283.8265\n",
            "# 15968, T 3539.1, Ltr 0.1839, Lge4 2.2847, Lge9 6.4953, Lge4_perm 159.8338, Lge9_perm 282.4099\n",
            "# 16058, T 3559.2, Ltr 0.2519, Lge4 3.4393, Lge9 4.0720, Lge4_perm 160.0907, Lge9_perm 282.3627\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}