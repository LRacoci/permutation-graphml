\section{Conclusions}

In the experiments we carried out, it was possible to verify meaningful differences in learning between not permuted and permuted test cases, where permuted test sets caused some neural networks to perform poorer.

Also, the algorithms seem to perform better if the problems being solved have no structural dependency between the computer representation and its actual real-world version.

An explored improvement for the invariance problem in graph representation is the use of permuted training sets for the networks, where the graph networks achieved better results.